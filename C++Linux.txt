#C++ (http://www.parashift.com/c++-faq-lite/index.html)
some::thing (scope resolution operator):
some is a namespace (in the global scope) and thing is a type, a function, an object or a nested namespace; 
some is a class available in the current scope and thing is a member object, function or type of the some class; 
used to define member(thing) out of defination of class(some)
in a class member function, some can be a base type of the current type (or the current type itself) and thing is then one member of this class, type, function or object.
classname(not instance)::static member
only ::thing can be  something in the global scope (out of all namespaces) : a type, a function, an object or a namespace. 
namespaces::type::member 
unique namespace that eliminates name collision, 'using' name from a namespace without the scope operator.
#include <string>
[using namespace std ;]
[std::]string s = "test me" ; 
#include <string.h>
char *strncat|char *str[n]cpy|int str[n][case]cmp|int strlen((const char *s1[, char *s2, size_t n])
char *str[r]chr|*strstr(const char *s1, int c|const char *s2)//in string s1 find first|last occurrence of character c|string s2, returns a pointer to that occurance in s1  
getch()/getchar()<stdio.h will let the output to be displayed till the user keyin a character/enter
printf<stdio.h> print info to the standard output 
#include <iostream> (cin, cout,cerr, clog)
myfile.open ("myfile.txt", ios::ate|app|trunc); point at the end|append to existing|truncated existing
ofstream inherites ostream (cout), so can write to files as well as console

Java, all methods, variables, named constants, etc. must be members of a class. In C++ not required to be, usually be placed be a namespace (default std::)  minimiz the potential name conflict. 

a==b | &a==&b compare value(content)|reference(address), content may contain diff padding bits for same value result in !=
bool RefEqual(const Class& a, const Class& b){  return &a == &b;}//&reference return address of managed object

compile optimize the switch statement much faster than if-else if 

char x='Y';while(x='Y')//accidental assignment:loop ever end instead of x=='Y'
int count; if(|count<100)//not auto initialized, never true 
; after class def, field not after function,if, loop, for(int x=0; x<100; x++);cout<<x; //100
double half = 1/2 | 1.0/2;//0 | 0.5   doublerec=((double)inta)/intb

singleton|auto& s = singleton::instance(); int|auto const i=100; auto [*]p = retPtr(), q = f();//p is pointer, q is [not]
auto x|[const] &x//work on copy|[not modify]orig

char|bool[8]:1 un|[signed]char [0|-128,255|127] (JAVA byte) equivalent to 8bits int<= short[16]:2 <= int[16,32]:4 <= long|float [32,64]:4<= long long|double [64,]:8  long double:12 //[bits]:bytes sizeof()
if(a>0&&maxInt-a>b || a<0&&minInt-a<b){return a+b; //avoid over flow
Floats store in memory:sign(+-)1 bit,mantissa(digits of number)24 bits,exponent 7 bits
floating point type: float(4byte) fValue =5e2|500.0f, double(8 bytes) dValue = 5e-2|0.05, represented number using a finite precision binary format approximation intead of real numbers (int does). precision : how many digits (default=6) it can represent without information loss  
due to rounding error (truncate the approximation due to limited memory: double dValue = 0.1;//0.10001), compare face-equal floating nums by == unexpected results, use below instead
 inline bool isEqual(double x, double y)
 { const double epsilon = /* some small number such as 1e-5 */;
   return std::abs(x - y) <= epsilon * std::abs(x);//#include <cmath> for abs
suffix f:float and u:unsigned int force the compiler treat the numeric as specified type instead of double and int
unsigned=unsigned int, int=signed int

floating point operations such as dividing by zero may produce special floating point values such as infinity and the not a number value (NaN: a numeric type representing an undefined value Signaling NaNs raise an invalid exception while Quiet NaNs do not as they propagate through most operations)
NaN is neither >,=,< any value including itself. for NaN a: a <>== b|a false regardless of the value of b. !(a < b) :true is not same to a >= b :false
 inline bool isnan(double x) { return x != x; } //<float.h>

union mytypes_t {  char c;  int i;} mytypes; elements occupy the same physical memory. The size decided by largest element.change one of the members affect other values
union [X]{
    int i;
    char c[sizeof(int)];//char c;
}x;
[X x;]
x.i = 1;
if(x.c[0] == 1)//x.c == 1    printf("little-endian\n");
else    printf("big-endian\n");

Little|Big Endian (Intel|Solaris): lower|higher significant byte of the number is stored in memory at the lowest address
L:in|decremented faster because write low end first.
B:compare faster because read high end first, while L must read through last byte(high end) to get result. 
The socket interface standard network-byte order is B so all network communication should be B, if processor uses L order. must call htonl|s(0x0a0b0c0d) to convert outgoing 32|16-bit value 0x0a0b0c0d to B before transmit over a TCP/IP connection, ntohl|s() to convert incoming value from network to L order. cause run-time performance penalties
   unsigned int i = 1;
   char *c = (char*)&i; // 1 byte char will contain only first byte of integer
   if (*c) //Little endian lowest byte 1 is stored first
   else //Big endian


main() is mandatory func returning an int. dynamic initialization of global variables is before main() 
must place callee class/func definition before the caller, otherwise compile err 'not declared in this scope', so c++ bottom-up: write main last

(public protected private static const volatile) not | apply to class/struct | members  
date member must NOT initialize in declare: class{private: int i[=0];
C++: struct = class except struct|class defaults to public|private inheritance and member access, can inherit each other 
C#: struct on stack, no inheritence, both can have member functions 
class a{ friend class b; within b.member can access a.private/protected member, not vice versa, used to split code into two partial classes

will[not] change the object structure, need [not] recompile calling code: un[safe]
a. add a constructor: safe
b. add a data member: unsafe
c. change destructor into virtual: unsafe 
d. append an argument with default value to an existing member function: safe 

storage qualifiers: (cv-qualifier: const, volatile, mutable  to any type, excluding function and pointers|references)
Const indicates that memory once initialized, should not be altered by a program.A mutable member of a const object can be modified without compiler error
struct data{char name[80];mutable double salary;}
const data MyStruct = { "Satish Shetty", 1000 }; //nonclass must assign on init 
strcpy ( MyStruct.name, "Shilpa Shetty"); // compiler error 
MyStruct.salaray = 2000 ; // ok

const{Const Functions to avoid accidental changes to objects by compile time check, if return references or pointers to members of the class, they must also be const. 
class Test {
    int value;
public:
    Test(int v = 0) {value = v;}
    int getValue() {
	value = 100;
	return value;
    int getValue() const {
	value = 200;//compiler error: change to object
	return value;
int main() {
     //const instance can not call non-const func (which may change state) of the object, err: passing xxx as 'this' argument of xxx discards qualifiers	
    [const] Test t;//const functions can be called on non|const objects
    cout << t.getValue();//100, 200 if only have const getValue() [200, compiler errors if no const getValue() : Non-const functions can only be called by non-const objects]
similar rule apply to const volatile Functions and objects   

void foo(int n){
constexpr int c1 = n+1;//err:must known at compile : results in a compile time constant value
    const int c2 = n+7;//ok  c2 = 7;//err:unchangable} : prevents from being modified

A volatile location indicate unpredictable value that can be changed by code beyond the control of compiler (such as hard ware kernel driver),compiler must read/write to actual memory per access without cache the content in a register that allow faster access than on-board memory, immediately reflect change on var used by multi thread
every access on volatile object considered has visible side-effect, so exempted from optimization (reordered or collapsed): X=1;X=0; for non-volatile object x, the compiler optimize only exe x=0 ).

?Define all shared objects as volatile.Don't use volatile directly with primitive types. instead, defining classes, use volatile member functions to express thread safety
on specific variable memory location.

Scoped enum class/strut  Wage|Tax{High,Medium,Low}; wont clash with each other by Wage|Tax w|t=Wage|Tax::Low instead of =Low old enum Wage|Tax {High=1,Medium=2,Low=3}; un-scoped constants; int i; switch(i) { case High: break;

Storage Specifiers:
auto (default) variable go out of scope once the program exits from the current {block}
register hints (not force) compiler to allocate some storage in the register faster access than on-board memory
static keep the var value upon re-entry into the same function,If this static variable is declared as a member of a class, then the value shared across all instances of the class,staic variables are allocated in global memory space with global variables.
(A static member function can access only static member, no virtual/override (that is tie to an instance's vptr but Static functions tied to a class) but can be inherited, no instance or 'this' pointer of the class. can be called When a class is not instantiated Cls::Foo(). static destor perform additional steps need to be taken upon destroying an instance)
class A {void foo() {
      static int i;//only one copy inside the program, i end by scope of program not foo, default init=0.
      i++;
A o1, o2;o1.foo(); // i = 1 o2.foo(); // i = 2
c++ no static constructors, must explicitly initialize the static member outside of the class (not subject to access controls)
class IDGenerator
{private:    static [const]  int s_nextID [= 1]; // a static const can be declared and initialized directly
 public:     static int getNextID();
};
int IDGenerator::s_nextID = 1; //all derived class use the same static member instance, no inheritance
int IDGenerator::getNextID() { return s_nextID++; }  
int main()
{    for (int count=0; count < 5; ++count)
        cout << IDGenerator::getNextID() << '\n';
Do not put the static member initialization in a header file (like a global variable) because each cpp file includes that .h get a own copy of var, redefine compile error.

extern tells the compiler it referring to a variable declared elsewhere (another file), do not allocate memory for it. mostly used to declare variables of global scope. 
destructor is called automatically when the program exits for static storage obj : defined outside a function (global var out of main) or keyword static. global variable has external linkage by default, a const global has internal linkage by default unless explicit extern const int a = 20;

Global - Static, global variables,
Stack - Stack frame (default 1MB) contains the local variables inside functions, params, automatic variables
Heap - Dynamic memory allocation

    int i = 5;
    int j = 1;
    *(&j + 1) = 0;//stack earlier in at higher address, &j + 1 is &i
    cout << "i: " << i << endl;//0 not 5

void func(int *p) {//int j;func(&j);
    int i;
    if (p < &i)        printf("Stack grows upward\n");
    else        printf("Stack grows downward\n");
}

class Base{};class Child:Base{int a}; 
void visit(Base* arr, int len) { for (int i = 0; i < len; i++) { Base a = arr;}//stack memory continously allocated by size of Base, unmatch if arr pass in Child instance

void foo(){foo;}//use all stack mem void foo(){while(true){malloc(0);}}//use all heap mem, malloc(0) returns/use a 4 bytes unique pointer pointing to zero bytes allocate nothing void foo(){while(malloc(1)){ } return;}//wont crash, malloc(1) allocates 4bytes 32bits returns a unique pointer if succeed, nullptr if no mem left

normal variables (auto) must be declared at compile time, life time is controlled by func scope,but difficult to conditionally declare a variable using if-- only exist within if block scope.
static int zz = 10 * x // not allowed, A static  initialized only with a constant expression, x is not constant
int anArray[nSize]; //compile err:  The size of the array must be a constant: int a[7]; sizeof(a);
int *pnArray = new int[nSize];//ok
Dynamically allocated memory (run time) is not controlled by scope{}. it stays allocated by new until it is explicitly deallocated by delete or until the program ends. internal mutex lock make new() thread safe because heap is shared among threads, used when memory size to be allocated is unknown untill runtime such as array, or exist out of func scope. so can be allocated from one function and freed from another function via passing by reference or pointer. However, the pointer/reference used to access dynamically allocated memory follow the scoping rules of normal(auto) variables. 

A* a = new A; delete a; is interpreted by the compiler as
A* a = ::operator new(sizeof(A)); 
try {a->A::A();} catch (...) {operator delete(a); throw;} // call constructor throw exception, auto deallocate memory

if ( a != 0 ) {  // a check is necessary for delete
    a->~A();
    ::operator delete(a);
}

type * pointer = new (nothrow) type [number_of_elements]//It�calls�operator new[](size_t) and the�class�default�constructor�for�each�element�of�the�array.�returns a non-null pointer to the first byte of this block.(nothrow)instead of throwing a bad_alloc exception or terminating the program, the pointer returned  a null pointer (p ==0/null), not point to anywhere, delete [] get the size_t from new[]. double** pvalue= new double* [row];//return pointer to 1st item of an array (row) of pointer each point to 1st item of an array (col) of double, char *string = new (nothrow) char[20]; if (!string) {..} delete[] string;delete [] pvalue; 

void g() noexcept {} If the function throws an exception anyway, `std::terminate` is called, destructors is implicitly `noexcept`

placement new constructs an object on a memory has already been allocated, to eliminate time cost of normal dynamic allocation by separate the allocation of an object from its initialization, don't want to wait for dyn alloc after realtime app start up. or to place objects at a fixed loc such as predefined memory pools or put global/static obj at hardware component (memory-mapped I/O)
   char *memorypool = new char[sizeof(Fred)];//use char[] to allocate mem because one char per byte
   Fred* f = new(memorypool) Fred();
   ...
   f->~Fred();   //only case need to explicitly call the destructor

to prevent an object being allocated dynamically(on the heap), by making its operator new private. Some classes must instantiated on the stack for auto clean up. For example, Boost scoped_ptr, or lock_guard.
class X {
private:
    void *operator new(size_t);
    void *operator new[](size_t);
};
? struct p{class c, new p still allocate c on heap even if c private new
to prevent an object being declared with auto duration (on the stack) , make all con/destructors private and provide friend or static functions or factory to create/delete instance.
class X {
public:
    static X *New() {return new X;}
    static X *New(int i) {return new X(i);}
    void Delete(X *x) {delete x;}
private:
    X();
    X(int i);
    ~X();
};

uncopyable class: private copy ctr and = operator,  default copy constructor|assignment operator of derived classes invokes the copy constructor|assignment operator of base class, so derived classes uncopable too because can not access to private member of base class.
struct Foo{ Foo() { } Foo(Foo&& f) { } private: Foo(const Foo& f) { } // uncopyable, Foo(Foo&& f) is for move};
declare the implicitly defined copy constructor and copy assignment operator of class as deleted functions make uncopyable class.
X(const X&) |  X& operator = (const X &) = delete; //disable

class Sig{
private:
    Sig(){}
    ~Sig(){}
    static volatile Sig* inst;
    static mutex mx;
public:
    static volatile Sig* getInst(){//consistent return type volatile
        if(inst==nullptr){
            lock_guard<mutex> lg(mx);
            if(inst==nullptr)
                inst=new Sig();
        }
        return inst;
    }
    static void dest(){//explicitly instead of ~Sig() to avoid being auto destructed
        if(inst!=nullptr) {
            delete inst;
            inst = nullptr;
        }
    }
};
volatile Sig* Sig::inst=nullptr;//static member must init out of class
mutex Sig::mx;

int main()
{   volatile Sig* si=Sig::getInst();
    //delete si; err:private destructor
    Sig::dest();//not si->dest()

C++ volatile not synchronize across thread as JAVA/C#

atomic<Singleton*> Singleton::instance;//guard variable for data instance 
mutex Singleton::mtx;

Singleton* Singleton::GetInstance() {
    Singleton* tmp = instance.load(memory_order_relaxed);
    atomic_thread_fence(memory_order_acquire);//right after load, = instance.load(memory_order_acquire);
    if (tmp == nullptr) {
        lock_guard<mutex> lock(mtx);
        tmp = instance.load(memory_order_relaxed);//only one thread should create instance
        if (tmp == nullptr) {
            tmp = new Singleton;
            atomic_thread_fence(memory_order_release);//right before store, = instance.store(tmp,memory_order_release);
            instance.store(tmp,memory_order_relaxed);
        }
    }
    return tmp;
}

name hiding:var refer|declare inherit|overide var with the same name at outter block{} scope
non-Dynamically allocated var destructors are auto exe when out of scope{}, in reverse order of construction,  at the close } of the block in which the instance was created,so do NOT explicitly call destructors, enforce destruction by wrap instance within a nest block {File f;}. 
Throwing exception out of a destructor can result in a crash, because Stack unwinding :a procedure takes place when an exception is thrown, all the local(auto) objects that were pushed into the stack since the "try" and till the thrown, will be terminated -> their destructors will be auto called  in reverse order of their construction to prevent mem leaks. because it's not possible to handle two exceptions at a time, if any of those destructor throws exception, the program will abort(), crash and the control will return to the OS. 
Virtual Destructor is need when class has at least one virtual function, so when we delete a child class via base class pointer (or reference) to the object, the program call the child class destructor followed by the base class destructor rather than using only the base class destructor
class B
{	[virtual] ~B(){ cout<<"Destroying B";}//empty virtual destor add a virtual pointer to instance
class D: public B
{      	~D(){ cout<<"Destroying D";}
void main()
{    	B *b = new D();
        delete b;//without 'virtual' only B destructor will be called, mem leak if D has dynamically allocated var to be released in D destructor, even not still result in Undefined Behavior 
destructor can't be overloaded: one destructor per class, it should NOT be multiple ways to clean up a object. if overloaded there is no way for runtime to choose which one to automatically  call since it has no argument/return. 
constructor Foo::Foo(char) can NOT call another constructor of the same class Foo::Foo(char,int)
throw an exception to handle constructor failure because Constructors don't have a return type.  
try{A();}//will be auto deallocated by stack unwinding if exception thrown frm ctor of A or within try block, not for dynamic alloc
if cstr has dynamic allocated pointer var, it will NEITHER be auto deallocated upon exception jump out of scope NOR by delete() defined in destructor because destr will NOT run if exception thrown from cstr, must use a smart pointer to deallocates memory
class Fred {
public: typedef std::auto_ptr<Fred> Ptr; //used as #include "Fred.h" Fred::Ptr instead of std::auto_ptr<Fred>, typedef define alias for a type to replace orig type in code, same as using Ptr = std::auto_ptr<Fred>; 
typedef stack<char> mstack; mstack& st;

Virtual Constructor not possible because when the constructor is invoked the virtual table is not available yet
order of contructor calls: ~member of base ~base ~member of derived ~derived, nest class not auto called
destructors: ~derived ~member of derived ~base ~member of base
main(){C c|C* c = new C()[B *c = new C]; cout<<"2";|delete c;}//0 1 2 3 4 [0 1 2 4 without virtual]
class C[:public B]{public: C(){cout<<"1";}  ~C() {cout<<"3";} [class B{public: B(){cout<<"0";};virtual ~B(){cout<<"4";};}]

Named Constructors = private ctor + public static methods diff name (paras with same type but diff mean) { call ctor
class Point
{
  public:
    static Point CreateRect|PolarPoint(float X|Radius, float Y|Angle){ return Point(X|Radius,Y|Angle); } // named constructor explicit the
meaning of Game(1|0)
  protected/private:
    Point (float v1,float v2) : f1(v1),f2(v2){};//private fields can store either Rect or Polar
    float f1,f2;      
};
   Point p1 = Point::CreateRect|PolarPoint(2.0,3.0); // Using named constructor
   Point p2 = Point(2.0,3.0); // does not compile
compiler auto implements default de/ctor,copy ctor,assignment operator =,address operator &, 
compiler will not generate a default constructor|assignment operator if the class declared any constructor or has const or reference members or his base class has unaccessible(no/private) default contructor|assignment. 

Initialization List : single copy constructor (of member) call without a separate copy of the object, exe before constructor  
Constructor Assignment : a temporary object created by default constructor call and passed into the assignment operator call
must use an initializer for any const or reference member becasue must be initialized/assigned upon declared (assign in constructor after declare not work). 
class foo
{   const int MAX_SIZE;
   int& ref;
public:
   foo(int& r):MAX_SIZE(128), ref(r) {} // right, duplicate to foo(int& r){...} 
   foo() {MAX_SIZE = 128; ref = r; }   // wrong

C++ initializes class members in the order they are declared, not the order they appear in the initializer list.
When there are dependencies in the order of initialization list, two order must be the same
class CMyClass {
    CMyClass(int i);
    int x;
    int y;
};
CMyClass::CMyClass(int i[=1]) : y(i), x(y) {}//initializer list: y=i with default value 1, x will have unpredictable value

fields are not auto inited, must manually 
class A
{private:    int i;    char ch;  int* ptr; char ar[2];  std::string str;
 public:    Base(): i(0), ch('\0'), [ptr(), ar()|{'a', '\0'}, str()]{} 
empty()|{}value-initialize:  so ar()make each element value-initialize, char isnot class so zero-initialize (a='\0' ptr=null), References cannot be value|default-initialize
{}list-initialize: aggregate (fxp array) initialization

struct T1|2|3
{   int i;    std::string s;
    //implicit default constructor|T2(const T2&) { } //explicit copy but no default constructor|T3() { } // explicit default constructor
}; 
value/aggregate-initialize T1|2|3 t1|2|3{};//t1.i|s zero|default-initialized 0|"", t2 error: no default constructor,t3.i|s default-initialized to indeterminate value|""
std::vector<int> v(3);  // value-initialization of each element that zero-initialize

default-initialize const T1|3 t1|3; //err|ok const require initializer or explicit default constructor,  t3.i indeterminate
const|int n; //non class err|indeterminate  string s|[2]; // class, default ctor|init element ""|{"",""}

A a = A(); ~ A *a =new A(); value-initialize if class default-initialize by default ctor; array/container each element value-initialize; nonclass zero-initialize
A a; ~ A *a =new A; default-initialize if class calls default ctor, array default-initializes each element, nonclass indeterminate, static non-class zero+default init=0
A a{};//aggregate-initialize A a(); declares a function,  not initialize an object
A a(5)|=5/A(5)/a1; string s1("test")|="test"; direct|copy initialize (string s2 = std::move(s1); ) by overload|then copy(move) constructor
A a=A(p);//overload ctr only  A a; a=A(p);//default ctr then overload ctr

http://en.cppreference.com/w/cpp/language/default_initialization
int n; // static non-class zero+default init=0
int main()
{int n;       // non-class, indeterminate
string a[2]; //array, default-initializes element by default ctor ("" empty string) similar to string s; class call default ctor
 
http://en.cppreference.com/w/cpp/language/value_initialization
int n{}; //nonclass zero-initialize 0
int* a = new int[10]|();//0s|0s  
int a[10]|{};//uninit|0s
//array value-initialization element by default ctor 0s same to vector<int> v(size); 
 
std::unique_ptr<int> p(new int(1));//direct-initialize, err:= new int(1);  constructor is explicit
struct F { int m; [explicit] F(int n) : m(n) {}}; //F f(2); F f = 2|'2';err if explicit, prevent implicitly converted single parameter to int call the F(int) constructor
explicit applies only to single non-default parameter constructors to suppress implicit conversion
explicit Foo( int x ) { _val = x; }
void func( const Foo& foo ){..}
func(10);// Acts like func( Foo( 10 ) ), int-to-Foo implicit conversion| compile error if explicit
 
   A a; 
   A b = a;|A* b=new A(a);| A b(a); /* copy constructor will be called when constructed and initialized together*/
   A c;//calls default constructor to static allocate on stack, auto destructed out of scope by stack unwind 
   c = a;|A *c=&a /* assignment operator will be called when already has been instantiated*/
   A *a = new A()|A; /* new operator called to dynamic allocate [arrays of] objects on heap, returning a pointer or A *a; a=new A(); delete a; explicit destruct*/

default copy constructor performs a shallow copy of cur obj (when pass/returns function argument by value), so class that has a pointer data member should apply deep copy implement a copy constructor,assignment operator=,a destructor 
class MyClass
{
private:
	char *m_str;// pointer member 
	int m_len;// non pointer member 
public:
	MyClass(char *pstr="")
	{
		m_len = strlen(pstr) + 1;// Plus one character for a terminator
		m_str= new char[m_len];
		strncpy(m_str, pstr, m_len);//constr deep copy arg to member
		m_str[m_len-1] = '\\0';// Make sure the string is terminated
	}
	~MyClass() 
	{
		delete[] m_str;
		m_str = 0;
	}
	MyClass(const MyClass& copySrc);//must declare b4 define
	MyClass& MyClass::operator=(const MyClass& copySrc);
	char* GetString() { return m_str; }
};
//compiler-generated copy constructor does member-wise copy of the source object,copy constructor must pass by reference,because if pass by value would again call the copy constructor again infinite loop,const reference not to change source object
MyClass::MyClass( const MyClass& other ) : intMember( other.intMember ), stringMember( other.stringMember ) {}
MyClass::MyClass(const MyClass& copySrc) 
{
	m_len = copySrc.m_len;//shallow copy non pointer member
	if (copySrc.m_str)//need to deep copy non-null pointer member 
	{
		m_str = new char[m_len];// allocate memory for our copy
		strncpy(m_str, copySrc.m_str, m_len);
	}
	else
		m_str = 0;
}

MyClass& MyClass::operator=(const MyClass& copySrc)// Assignment operator take and return ref MyClass& 
{
	if (this == &copySrc)// check for self-assignment: if this pointer to the same address of the referencing object copySrc
		return *this;//return this returns a pointer to the object, return *this returns a copy|reference of the object based on return type MyClass|&
	if(m_str!=copySrc.m_str)//otherwise delete m_str will delete copySrc.m_str  
		delete[] m_str;//dynamically allocated variables, need to deallocate old memory before allocate any new memory to avoid leak
	//same as deep Copy constructor
	m_len = copySrc.m_len;//non-dynamically allocated variables (fixed size), the new value overwrite the old one
	if (copySrc.m_str) 
	{
		m_str = new char[m_len];
		strncpy(m_str, copySrc.m_str, m_len);
	}
	else
		m_str = 0;
	return *this;//return a reference to the current object
}

int  main ( int na, char * args[])
{
	MyClass cTest("test");
	{
		MyClass cCopy = cTest; 
		// use default shallow copy constructor if no deep Copy constructor, cTest.m_str and cCopy.m_str point to the same mem
	} // cCopy goes out of scope here, MyClass destructor is called on cCopy, that mem get deallocated 
	std::cout << cTest.GetString() << std::endl; // this will crash when refer to that mem again
        cTest = cTest;//use assgn op, if no self-assignment check, delete[] this.m_str will delete cTest=copySrc.m_str
	getchar();
	return 0;
}

vector2 = vector1;//vector<Special*>  copies only the adress of the pointers (shallow), deep copy need impl clone:
vector2.resize(vector1.size());
for(unsigned i = 0; i < vector1.size(); ++i){ vector2[i] = vector1[i]->clone();

class Special : public Super
{
public:
    Special() : Super() {};
    Special(const Special& _rhs) : Super(_rhs){};//chain para ctr as default ctr
    virtual Special* clone() const {return(new Special(*this));};
};
Special* a = new Special(); Special* b = a->clone(); // copy of a

int *o = new int; //default initialize: indetermined o:600|700 700|6677667
int *p = new int(99); 
int *q = p;    //shallow copy only copy the pointer, not the memory it points, ~ int *q; q = p; need not * to assign address 400, p:100|400 q:200|400 400|99
*o=*p; //o:600|700 700|99 o=p; //o:600|400 
int *r = new int(*p);  //deep copy: allocate a new int before copying the value pointed to by p, r:300|500 500|99
*p = 100;      //need * to assign value *q=100, *r=99
int &s=*p;
int* r=&int();//only can address on lvalue, both invalid    int& o=int(); 

Pointers and references are variables hold memory addresses of certain type.   
&x  reference operator "get address of x" only on right side <> int& r; declaring a reference
*p  dereference operator "get value pointed by pointer" only on right side <> int* p; declaring a pointer 
References are implicitly const *pointer, must be assigned to an existing var(address) upon declaration, and can not be reassigned to another var(address). not addressable (&ref returns the address of the object not reference int  x = 5;int& y = x; cout << &x << &y << "\n";//print out the same address), change value of reference  == change value of underlying var, commonly use as para to signify an object that is not copied when pass to a function, const &r can not even change value, so para value wont be unexpectedly changed within the func and reflect back to caller, Pass para by non-const reference ONLY if the function will modify the parameter. non|const t can pass to f(const T& t){no change t}, const t can NOT pass to f(T& t){change t}
non-const references cannot bind to temporary objects (without a variable name), so foo("t"); complie ok on void foo( const std::string& s ) but err on foo( std::string& s ), because compiler try to construct temporary std::string from "t". 

ptr|ref para can|not be null(0), f(&p); f(p); can|not diff from by value para, ref|ptr can|not used in operator overload & copy ctr, so no s=&a+&b for ptr, const ref|ptr can|not accept temp object to avoid copy, usualy const ref for input para only, ptr for in/out para, ref/ptr use more mem than char byte int   
int ival = 100;
int iVar1;//memory allocated but val not intialized ~int *p = new int; 
int iVar2 = int();//val intialized default 0 ~int *p = new int(); 
int &rval = &ival;    // Error: address
[const] int &rval = 100;    //[ok A temporary is created behind scene same as =int(20)] Error: cannot convert from 'int' to 'int &', must init to an address, same as call foo(100); to foo(int& a) 
int &rval = ival; //implicitly get address of ival, same as int* pval=&ival|new int(); int &rval = *pval; but err int &rval = pval|new int(); becasue new return pointer/address
rval = iVar2;//not reassign rval to ivar2 address, assign ivar2 value to rval's ref var ival=ival2=0, rval (alias replaces ival) still refer to ival, err if int const &rval 
int &rval2;        // Error: uninit
int &rval2 = rval; rval2=200; //rval2 also refer to ival = rval =200, same as pass/return ref to ref
double dval = 3.14;
rval = dval; //Error: cannot convert from 'double' to 'int &'
const int &rval3 = dval; //conversion is done by the compiler using temporary object 
char *a=nullptr; char& p = *a;//The result is undefined. A reference must always refer to a object/address, can not be null/0
use references to simplify access to nested class memeber int &rnValue = pcls.ccls.mem;

A pointer can be declared witout initialized which is not recommended, int* p [=nullptr]; effectively point to NULL/0 (C++11 prefer constant literal nullptr), can be reassigned.
void f(int);void f(char*);
void g() {  f(0); //calls f(int) f(nullptr); //calls f(char*)}
A const pointer always points to the same address, must init on declare: int *const pnPtr;//err

void/generic pointer void* to some memory that the compiler doesn't know the type of. can be pointed at any type and nullptr, cannot be dereferenced directly must first be explicitly cast to another pointer type before it is dereferenced. (so no void reference.) used to transmit an address between codes that don't know each other's type.
int value = 5;void *ptr = &value;  
int *intPtr = static_cast<int*>(ptr);cout << *intPtr|*static_cast<int*>(ptr) << endl;  
nullptr pointer to no memory,  deleting it doesn't do anything but delete not-null pointer more than once cause err 

Fred const* p == const Fred* p is pointer to a constant Fred (read backward): the Fred object can't be changed via p.
Fred *const p is a const pointer to a Fred: you can't change the pointer p (address), but you can change the Fred object via p. 
Fred const * const p== const Fred * const p is a const pointer to a constant Fred, same as constant reference (reference to constant) Fred const &p | const Fred &p 

volatile int* pv= &somevolatileint; //pointer to volatile int, err if use int* pv which cause it to be cached when access somevolatileint via *pv
int* volatile vp; volatile pointer to int, not to cached ptr content (address) when is assigned
volatile int * volatile vpv;

int x=1,y=2;
int *p; 
p = &x; //x:100|1 y:200|2 p:1000|100 &p(1000)p(100)*p(1)
[*p = y; //p still point to &x, x value change to y]
y = *p; //x:100|1 y:200|1 p:1000|100, y<=x value that p point 
x = p;  //x:100|100 y:200|1 p:1000|100 //uncommon op
*p = 3; //x:100|3 y:200|1 p:1000|100 3=>x value that p point 
int **q; q=&p;//q:2000|1000 &q=2000 q=1000 *q=100 **q==3

int *ip;
[ip = &x;]//crash without [the stmt also Potentially Dangerous], but NO COMPILER ERROR: MUST have an address for a value to sit.
*ip = 100;//ip = 100; cast compile error: expect address

int* p=0|1;//0K same as NULL nullptr | cast compile error : expect address

white space around * & is ignored so int* p same as int *p, only to immediately following variable, double* v1, v2; only v1 is pointer v2 is double, double *v1, *v2 both pointer
p->m == (*p).m <> *p.m == *(p.m) 

void foo(double* r)//can not determine whether points to a single instance or an array of instances, *ptr is equivalent to ptr[0]
{    *r = 3.7;//single or array both legal: for (int i=0 ; i<3 ; i++){ r[i] = 0.0;} 
void foo(double& r)|(double r[]){r = 3.7;| for (int i=0 ; i<3 ; i++){ r[i] = 0.0;}//use reference (no need & for array) for clarity
double* p = new double[3]{1.0,2.0,3.0};//int p[3]={1,2,3}; 
foo(p); //assign pointer with an array name (initial elements pointer) same as double* r; r=p; work for reference too
does not allow to return an entire array, only by pointer
int * getRandom( ) //not int[] getRandom( )
{ static int  r|r[10];//must static otherwise dangling pointer
  r=1|for (int i = 0; i < 10; ++i)  {    r[i] = rand();  }
  return &r|r;//match int *, an array name r is a constant pointer store the first element address &r[0]
}
int *p; p = getRandom();
for ( int i = 0; i < 10; i++ ){cout << *(p + i) << endl;}

class test {public: long ar[]; long ar[2]; long ar[2][3]; long* pr;//declare array of long, uinit/undetermined|0 on default|value-init if []/[2], 2D must has size, name ar is a pointer to array head, pr can point to 1/2D  
   test (int x, int y) { this->pr = new long[x][y]; }
   ~MyClass() {delete pr; }

auto array = new double[M][N]|();//declare|init ok in C++11,int** array = new double[M][N];//wrong
int array[M][N];//ok but uninit cannot access item before assign value 

int* test(size_t& arraySize) {array_size = 10; return new int[array_size];}//temp object error if without new (local instead of dynamically allocate), return array as ptr with size otherwise size unknown to caller 
size_t theSize = 10;int* theArray = test(theSize);for (size_t i; i < theSize; ++i) {...} delete[] theArray; // still ok.
 
vector<int>|array<int, 2> test() { vector<int> vector(10); return vector;|return {3, 4};}
//vector<int>|array<int, 2>  (Return Value Optimisation or const reference readonly to avoid copy) const vector<int>& v = test(); for (auto
it=v.begin(); it != v.end(); ++it){..}, auto delete
 
2D array:   int rows = sizeof(arr)/sizeof(arr[0]);    int cols = sizeof(arr[0])/sizeof(arr[0][0]);
void proc2D(int **arr, size_t rows, size_t cols){for (size_t i|j = 0; i < rows|cols; ++i|j){cout << array[i][j];
 
vector <vector<int> > vec2D(5, vector<int>(4, 1));//5x4 1,1,...
for(auto vec : vec2D)
{for(auto x : vec)  std::cout<<x<<" , ";}
for(int i=0; i<vec2D.size();++i){//row=5
    for(int j=0; j<vec2D[0].size();++j)//col=4
        cout<<vec2D[i][j]<<",";
}

    const size_t row=3,col=2;
    int av[row][col] = { {0,0}, {1,2}, {2,4}};//static: { 0,0,1,2,2,4} unchangable size must be known at compile-time
    //int *ap = new int[row][col];//wrong
    int **va=new int*[row];//dynamic: size can be variable
    for (int i=0;i<row;++i) {
        va[i] = new int[col];
        //std::fill_n(va, row, -1);
    }
    va[1][2]=1;
    for (int i=0;i<row;++i) {
        delete[] va[i];
    }
    delete[] va;//multi delete must match multi new

double** arr;
arr = (double**) malloc(row*sizeof(double*));
for (int i = 0; i < row; i++)
   arr[i] = (double*) malloc(col*sizeof(double));

    vector<vector<int>> vv{ {2},{3,4},{5,6,7}};
    vector<int> vr; vr.push_back(1);vr.push_back(2);
    vv.push_back(vr);
    vr.clear();
    vr.push_back(3);vr.push_back(4);
    vv.push_back(vr);
    vv[2][1]=4;
    cout << vv[2][1] << endl; //4
    array<array<int,col>,row> aa {{ {1,2},{3,4},{5,6} }};
    aa[1][2]=1;
    //void foo(std::array<std::array<int, 3>, 2>& arr){} foo(aa)

char msg[ ] = { 'a', 'b', '\0' }//necessary marking the end by \0 for runtime to terminated 
C++ runtime cannot determine the length of an array, no exception when accessing outside the bounds so foo(int[] ar, int size | sizeof(ar)/sizeof(int)), unlike Java ar.length or for(int i : ar), it check outofbound each time access an element direct read/write a[i]. 
vector at()|operator[] slow|fast becasue check|not array out of bounds (exception if so) 

C++ object and arrays can be allocated on the stack via declaring or heap via "new". Java only allocated on heap via "new"
Cls buf[20]; Cls* buf = new Cls[size];//only call default no-parameter constructor,compile err if declare any other constructors so no-parameter constructor is not auto generated
Cls* buf[20]; 
for (int i=0 ; i<20 ; i++)
    buf[i] = new Cls(i);//call parameter constructor 

[static] int a[5];//all [0] uinit val int a[5]{0}|={[0]};//all 0  int a[5]={1,2}//1,2,0,0,0 <algorithm>std::fill_n(a, 100, 1);
int a[] { 1, 2, 3 };int* a = new int[]{ 1, 2, 3 }; vector<int> vi{ 1, 2, 3}; vector<string> vs = {"ABC", "BAC", "CAB"}; vector<int>* vp =new vector<int>{ 1, 2, 3};//init
#include <algorithm>
std::sort(a, a + SIZE); std::sort(std::begin(a), std::end(a));  for(int n: a){ cout << n << ' ';}
std::sort(std::begin(vs), std::end(vs)); for (string &s : vs){ cout << s << " ";}
std::sort(vi.begin(), vi.end(), std::greater<int>()); for(const int &i : vi) { cout << i << ' ';}//sort desc, vp->begin|end() 
if (std::binary_search (vt.begin(), vt.end(), 2)){//found
std::fill_n(a, 3, -1); vi.fill(-1);

char* s = new char[size][{'H','I','\0'}];char arr[size];//il|legal in g++|C++ char arr[3] [=] {'H','I','\0'}; char arr[]| = "HI"; //il|legal 3bytes, const char *s("HI"); string str(s);
#include <cstring> strcpy|cat|len|cmp|str(s1, s2);strchr(s1, ch);//char * ([const] char *s
#include <string> string str = "HI"; str1+str2;str.append|copy(=)|size=length|compare(== value)|find|substr(); std::to_string(int|long|double), stoi(string),string::data|c_str() both return char* to inner array
string sStr("01234567");Length: 8 Capacity: 15 sStr += "89abcde";Length: 15 Capacity: (no reallocate) 15 sStr += "f";Length: 16 Capacity: 31 (reallocate & copy, invalid old pointer/reference/iterator, avoid by string sStr(32,"01234567"); sStr.reserve(32); later .shrink_to_fit();)�01234567� string 8+\0=9bytes+size4bytes align with 64bit(8bytes) to 16 bytes
string.erase(std::remove_if(string.begin(), string.end(), ::isspace), string.end());//<algorithm>,  err on std::isspace
std::string will always manage it's internal storage with new/delete on heap by default allocator vs char[] can be allocated on stack, small string optimisation (SSO) each string object contains a small buffer so short one can be stored entirely within the string object and do not require a separate heap memory allocation. 
Java String objects are immutable whereas C++ std::string objects mutable void update(string|& str){str += "!";} not|reflect to caller update(st);, == value equal

char *ps = &s[0];//ps point to char array s[], == char *ps; ps=s; 
s|ps[i] == *(s|ps+i) &s|ps[i] == s|ps+i  
foo(s | &s[0]| &s | ps);  
void foo(char s[] | *s)
{ char *p = s;

char* a | char a[]= "abc"; // a string constant/literal can't be modified, a store the address of 'a' | copy string literal into array.
a[0] = 'c'; //runtime err|ok

void f(char*& | ** p)
{p | *p="Hello";//= new char[5] return a pointer to first item, p:b4|00 b4|b0->b0|H | 2c|b4->b4|00 2c|b4->b4|b0->b0|H 
int main()
{	char* i=0;
	f(i | &i);//i:b4|00 b4|b0->b0|H  
	std::cout << *i|i << '\n';//H|Hello output the first item|whole array 

comparing to char* (suit for underneath perf tune), std::string has auto memory mgmt, buildin functions (compare,find,replace,substr), .length make operation like copy append faster by avoid iterating through the entire character array looking for the terminating NULL character

can increment or decrement pointers to iterate element in array
++*p++;//first exe p++ increment address value of pointer, int/float* 4 bytes, char* 1 byte per add,then ++*p increment content value (i if not p++) currently pointed by pointer. 
++i++;//compile err: first exe i++ returning a temp obj that will vanish right after exe so ++i can not
i++ increment i, but return the pre-incremented value.++i increment i, then return the incremented value. i = i++|++i;cout << i; //0|1
for (int i = 0; i < 3; ++i|i++){0 1 2 are same, i++ slightly slower create a temp copy of the pre-incremented value

all pointers occupy the same memory (4|8 bytes on 32|64-bit machines) allocated on stack no matter target types (char*|int*) while its value store begin address on heap for target type mem, only different when read or set mem from that address to 1|4 byte accordingly
so pointers mem auto freed when out of current func scope, but not the heap mem being pointed.    
NOT return a local pointer variables (unless dynamically allocated by new) mem freed upon exit func and left A dangling pointer to mem  has been freed and may already been allocated differently, may cause memory corruption such as a virtual function call, a different address may be called due to the vtable pointer being wrongly overwritten. avoid by smart pointer 
  char *dp = NULL;
   {   char c;
       dp = &c;
   } /* c falls out of scope dp is now a dangling pointer, unless dp = 0 /NULL;} */

void func()
{   char *dp = malloc(A_CONST);
    free(dp);         /* dp now becomes a dangling pointer, unless dp = 0 /NULL;} */
}

    char *dp;    /* without initialization, dp is a wild pointer */
    static char *scp;  /* scp is not a wild pointer: static variables are initialized to 0/

Compiler Warning: returning address of local variable or temporary A function returns the address of a local variable or temporary object. they are destroyed when a function returns, so the address returned is not valid.
int* badPointer() {[static] int i;return &i;}//the pointer &i is no longer valid (unless static or dynamic alloc int* i= new int();return i; ) i is dealocated upon exit scope
int& badReference(){[static]int i=5;return i|5;}//err When the call ends, the reference and local i are destroyed unless static, return int const & error too.{int* i=new int(5);return *i;}//ok 
no worry pointer/refernce to auto allocated locals passed to other func, will be deallocated when out of outer scope, pointer to dyamic allocated (always in place for reference) passed to other func hard to determine which func or copy of pointer should be used to delete, so need use auto_ptr to pass unique ownership, final owner (auto) delete resource  
void memory_leak() 
{    ClassA * ptr = new ClassA;
    ...//if have return inside or an exception > mem leak, unless use try catch{delete ptr;} or auto_ptr 
    delete ptr;
//without delete: after ptr is auto destroyed when out func scope there are no references to that dynamically allocated memory, simlar leak when reassign ptr to anoter address before delete 
    delete ptr;//attempt to deallocate a deallocated mem will cause a crash 	
    if (ptr)//delete won't set ptr to 0 NULL so still true unless explicitly set ptr = 0;
     *ptr = 5; //assign to a deallocated mem will cause a crash: Segmentation fault, but ok repoint to another address ptr=&b;
} 
Memory Leaks:unintentional occupied memory(can be detected by tool Rational Purify), Buffer Overruns (memory outside of the allocated boundaries is overwritten), Uninitialized Memory (try to read variables without an initalized value),Incorrect Memory Management (delete/free() a mem more than once, access memory after freeing it, or free a memory that was never allocated. use delete instead of delete[] to free an array >data corruption, or wrong mix use malloc() with delete or new with free(), Null dereferencing/access invalid mem (Trying to use -> or * operator on a NULL pointer/not allocated yet/freed already).
memory corruption : program writes data to the wrong memory location,

dynamic memory allocated during runtime without having to know the number of variables should declare (array, struct,class). while(p){...p=0;}

�this� is a const pointer, is a hidden parameter of any class member points to the instance it is working with., do NOT delete this > The object's destructor is invoked, ~C() {delete this; } >infinite loop
If the object wasn't allocated using 'new', or If any of object's data members or virtual functions are accessed after 'delete this', the behaviour is undefined.
class Calc
{private:
    int nValue;
 public:
    Calc(int nValue) { this->nValue = nValue; }//differentiate a member variable from parameter of the same name
    Calc& Add(int nValue) { this->m_nValue += nValue; return *this; }//chained cCalc.Add(5).Sub(3)
    Calc& Sub(int nValue) { this->m_nValue -= nValue; return *this; }//return a reference to the current object : content where 'this' is pointing

default argument (part of signature) must start from right most void foo(int x, int y = 20)//ok void foo(int x= 20, int y )//no
void display(char = '*', int = 1); display(�$�) ok display(1) no

Java only "pass by value|reference" for primitive|object(including arrays) types
C++ pass by value and reference" for both primitive and object types, arrays can only be passed by reference (no need '&') 
   Employee fred[ = new Employee( )]; //C:allocated on stack[Java:allocated on heap]
   proc(fred);

void proc(Employee b) //Java(a reference copy to the same instance fred) C(a copy (C11:move-construct) from the orginal instance fred) 
{Employee a; //Java(allocated a reference, not Employee instance,on stack) C(allocate a new Employee instance on stack by default paraless constructor)
 a = b; //Java(make a refer to the same instance of Employee as b refer to) C(copy data of instace b to a by assignment operator
 b.trans(); // Java(modify the same instance of Employee as a.trans();) C(modify on seperate instance than a.trans();, neither wont affect the orginal instance)

Arguments passed by value can be variables (eg. x), literals (eg. 6), or expressions (eg. x+1). can return local var as a copy 
When a derived class object is passed by value as a base class object, as in foo(Base derived_obj), the base class copy  constructor is called to create the object. same as upcast a derived object to base object instead of a pointer or  reference,  So, extra member and polymorphysm of a derived class object are sliced off

return|Pass by reference because not copying arg (esp.large structs/classes) faster than pass by value, can return multi values via arg, dereferencing a pointer is slower than accessing a value directly,can not literals or expressions, return var must be non-local or dyn mem because scope
int& foo([const]int & x ){X=...// return|pass by reference foo(aValue); avoids the slicing prefer over by value (if not built-in /STL types), safer prefer over by address, const:avoid unintentional changes via compile err.  
int* foo(int *p){if(!p) return; p[0]=|*p=...; (check : Dereferencing a null pointer crash program) return &var;//return|pass by address|pointer foo(anArray|&aValue|*p); address|pointer arg is actually passed by value (create local copy of arg pointer to the same memory, function change to that memory will reflect back) unless pass reference to a pointer foo (int *&p) to reflect back change to address of p, 
define func argument = declare variable, white space around &/* is ignored, pass argument = assign variable
int y=10;
void F(int* x)			|(int& x)	|(int** x)				|(int*& x)//reference to pointer (read backward) pass the same pointer instance
{x=&y;//y=10	|*x=y;//ref bak	| x=y;		|*x=&y;**x=4;//ref bak			|x=&y;*x=4; //ref bak, syntax same as direct use the pointer
 *x+=5;//y=15, 	|x = new int(4);//not ref bak	|*x=new int(4);//ref bak		|x = new int(4);//ref bak x:[28|94->]94|a0->a0|10 94|b0->b0|4
int main()	|x:28|a0->a0|10	28|b0->b0|4	|x:28|94->94|a0->a0|10 x:28|94->94|b0->b0|4
{int y=20;
 F(&y);//y=20	|//y=10		|F(y);//y=10			 
 //equivalent: int* p; p= &y;F(p); pass a copy of pointer (either an address or a pointer has been assigned address), within func a new pointer is allocated diff stack address and point to the same heap address 	
 F(p);//*p=10 p:94|a0->a0|10|	|F(*p);		|F(&p);//*p=4 p:94|a0->a0|10 94|b0->b0|4|F(p);//p=4, pass orig pointer p:94|a0->a0|10 94|b0->b0|4
pass arg to para = declare + assign para to arg: p=&a:&a>(*p) &p=a:a>(&p) 
pass a copy of pointer argument, reassign it to another addr will disconn from orig value

const_cast manipulates the const attribute 
char ch = static_cast<char>(48);//pointers or references upcasting only, 
Parent *pParent = &child|new child(); //implicit upcasting for a base-class pointer (reference) to refer to a derived-class object,   
Child *pChild =   &parent|new parent();//downcast won't compile,assigns the address of a base-class object (Parent) to a derived  class (Child) pointeris unsafe, new members in derived class wouldn't apply to the base class. 
static_cast doesn't do run time type checking, used when sure about an object type like reverse an implicit upcasting conversion upon passing argument,or between fundamental types: explicitly suppress comiler complain about unsafe, data loss
dynamic_cast do run time type checking > slower
Child *p = dynamic_cast<Child *>(pParent)//safe downcasting w/ runtime cost: returns the address of the object if it can cast, otherwise return 0 NULL ptr.
used only with pointers and references to objects,Parent must has virtual member (polymorphic) otherwise compilation error 
will never throw a structured exception (std::) when used with pointers, but it will probably throw an unstructured exception that you cannot catch when passed an invalid pointer.  
if(p) {// we can safely use ptr 
reinterpret_cast (ultimate cast disregards type safety) converts any pointer type to any other pointer type, even of unrelated classes
Nested classes are useful for organizing code and controlling access and dependencies
Local class is a class defined within the scope of a function, useful for managing code dependencies

using STL collections in 'old C++'
storing objects by value, a lot of overhead if the objects are large and thus being copied around.
storing objects with pointers,  adds a whole lot of memory management issues

C++11 http://www.aristeia.com/EMC++.html 
C++11 when pass/return expensive-to-copy object to/from function, the orignal no longer needed after secondary is created, move content instead of copy (extra memory) or pointer (memory management) to lower cost when the object is an rvalue or the object's class defines move functions 
An lvalue is an expression that refers to a memory location and allows us to take the address of that memory location via the & operator (has identity can not be moved from). rvalue is not (has no identity and can be moved from)
int i = 42;  int* p = &i; // ok, i is an lvalue int* p = &(i + 3)//err, rvalue not addressable
int|& getr|lValue (){...}; //is r|lvalue because int* p= &getr|lValue(); err cannot take address of an rvalue|ok
an rvalue is An expression that results in a temporary object which can not be taken address of, because temporary object remains alive only until the end of the full expression in which it was created, it is no where to get the orig address afterward. but if bind a const reference to temporary object, it remains alive as long as the reference is alive. it is illegal to bind temporary object to non-const reference
non-const rvalue reference T&& refers to temporaries that are permitted to be modified after they are initialized.
int&& rvalue_ref = 9 or f()|i;//ok|cannot bind an lvalue to an rvalue reference 
[const] int& ref = 9 or f();//int f() { return 1;} return is rvalue, without const:invalid initialization of non-const reference of type int& from an rvalue of type int
void f([const] int& i); //non-const lvalue reference binds to an permanent object. const lvalue reference accept both lvalue or rvalue.
void f(int&& i);//rvalue reference binds to a temporary object which typically will not be used again.
    int i = 77;
    f(i);    // lvalue ref called
    f(99);   // f(getrValue());rvalue ref called
    f(std::move(i));  // rvalue ref called
The main usage of rvalue references is to create a move constructor and move assignment operator to avoid unnecessary copies the temporary which will go away.
the compiler chooses between the copy constructor and the move constructor based on whether the argument to the assignment operator is an lvalue or an rvalue.
a = b, the copy constructor will initialize that (because the expression b is an lvalue), and the assignment operator swaps the contents with a deep copy. then get rid of the copy by leaving the scope.
a = x + y, the move constructor will initialize that (because the expression x + y is an rvalue), so there is no deep copy involved, only an efficient move. that is still an independent object from the argument.

the copy constructor makes a deep copy, because the source must remain untouched. 
The move constructor, can just copy the pointer and then set the pointer in the source to null. It is okay to "nullify" the source object because it won't be acessed again.

class MyClass {
   unique_ptr<int> buffer;//int* buffer = nullptr;
   string data;

public:
   // move constructor
   MyClass(MyClass&& other) {
      buffer = other.buffer;//swap instead of copy as regular copy constructor
      other.buffer = nullptr;
      data = std::move(other.data);//other.data is empty after this
   }
   // move assignment operator, if = rvalue, move is used instead of copy
   MyClass& MyClass::operator=(MyClass&& other) {
      if(this != &other) {//compare address, impossible for temp obj, unless bug should assert(this != &other);
         if(buffer) {
            delete buffer;//assign used to inited instance that need to be cleaned vs copy to uninited that need not
         }
         buffer = other.buffer;
         other.buffer = nullptr;
         data = std::move(other.data);
      }
      return *this;//MyClass& implicitly get address of object this pointing to
   }
};
default operator=(const Datas&)' is implicitly declared as deleted if declares a move constructor or move assignment operator
STL such as vector overloaded push_back(const T& | T&& )for lvalue | rvalue arguments to be copy|moved if the element class defines move constructors.
MyClass aObj;   
mvector.push_back(aObj);  // push_back(const T&) aObj permanent object lvalue
mvector.push_back(MyClass()); //MyClass() is temporary object, push_back(T&&) moves rvalue  argument into vector's element MyClass objects using MyClass's move constructor.
mvector.push_back(std::move(aObj)| std::forward<decltype(aObj)>(aObj)); //push_back(T&&) 
move(t) cast l|rvalue to rvalue reference while forward<T>(t) cast to either an lvalue or rvalue reference but can not cast an rvalue to lvalue, mandatory <T> contains the information whether std::forward should restore the rvalue-ness 

myvector.emplace_back(args); allowing non-copyable / non-movable elements by regular constructor (args) in place of container by forward the arguments to the container  plus myvector.emplace/push_back(t|T(args)); take an existing lvalue | regular constructor (args) rvalue a temp object and copy(const T &) | move(T &&) constructor it into the container.since unique_ptr has move but no copy constructor due to single ownership, can only constructor a temp unique_ptr<MyClass> and std::move(existing unique_ptr<MyClass>) to rvalue 

When call emplace_back with para not rvalue references, it 'falls back' to normal references and  copy ctor T(const T&) is called instead of move ctor T(T&&)
string mystring("foo"); vector<string> myvector;
emplace_back("foo") in-place-construction calls string(char const*)
push_back("foo"|string("foo"))  first call constructor string(char const*) then move-constructor
emplace_back(mystring): in-place construction with provided argument, an lvalue map to a copy-construction, == push_back(mystring)
push_back(std::move(mystring)): move-insertion, string is an in-place move-construction.
emplace_back(std::move(mystring)): in-place construction with an rvalue calls the move-constructor of string, in-place move-construction ==push_back(std::move(mystring))

struct foo{    explicit foo(int);};
    std::vector<foo> v;
    v.emplace(v.end(), 10);      // Works
    //v.insert(v.end(), 10);     // Error, not explicit
    v.insert(v.end(), foo(10));  // Also works

vector<unique_ptr<int>> pi.emplace_back(new int);If reallocation is required and it fails, new object never went into the container and will thus be lost leak.

auto|T&& universal reference  Cls|<T>&& rvalue reference
An rvalue reference can bind only to an rvalue, but can use it as an lvalue because exclusively own that value, int&& t = 3;     ++t;
T ret(void){T t; return t|T();} T&& r=ret(); const T& r=ret(); T r=ret();//move|copy ctr,  returned temp outlive r,  
(Named) return value optimization (NRVO) copy elision eliminates copy/move construction: copy local auto object t to temp object for the return value of ret() and copy/move (if move ctr available) of that temp object into object r, t constructed directly in the storage of r. will be inhibited by return std::move(tmp);  
T&& ret(void){T t; return std::move(t);} T&& r=ret();//err: r refer to destructed tmp inside the function
int increment(int[&&] x) {  ++x;  return [move](x);}//only need move on [case]

template <class T>
//T need move constructor(T&&), otherwise move will use the implicit copy ctr (const T&) instead , move ctr not accept (const T&&) because need to modify T, copy ctr still be used if move const  
swap(T& a, T& b) {
    T tmp(move(a));//move constructor instead of copy
    a = move(b);   
    b = move(tmp);//move assignment
}
int|string a=1|"a";int|string b= move(a);

Swap a(v1) b(v2) a=a-b=v1-v2;//instead of a=a+b may overflow b=a+b=v1-v2+v2=v1; a=b-a=v1-(v1-v2)=v2;

perfect forwarding:template function f can pass its arguments through to another function g whilst retaining the lvalue/rvalue nature of arguments to proper overload
void g(Y|X&|X&& t); //overloads for value|ref(l|rvalue) 
template<typename T>
void f(T&& t){    g(std::forward<T>(t));} //T&& universal references: template function dont have to overload as g
    X x; Y y;
    f(x);   // named/permanent, T is deduced to an lvalue reference X&, std::forward pass it thru > lvalue-reference overload
    f(X()); //temporary, T is deduced to be plain X, std::forward cast to rvalue >rvalue-reference overload
    f(y); //by value version	

avoid to write several overloads of functions to support move semantics and copy semantics.
foo f;
multimap.emplace(std::make_pair(std::move(f), string("a")));// uses pair's move constructor
template<class U, class V> pair(U&& x, V&& y);
Effects: The constructor initializes first with std::forward(x) and second with std::forward(y).

struct X
{
    X() { cout << "ctor" << endl; }
    X(const X&) { cout << "copy ctor" << endl; }
    X(X&&) { cout << "move ctor" << endl; }
};
struct Wrapper
{
    X w;  //X() 

    Wrapper(const X& v) : w(v) { }   //X(const X&)
    Wrapper(X&& v): w(std::move(v)) { } //X(X&&)

    template <typename Q>
    Wrapper(Q&& v) : w(std::forward<Q>(v)) { }//fwd to proper sig based on orig arg  
};
Wrapper w1(X{ }); //will move ctor instead of copy ctor

useful for std::function and std::thread which pass arguments to another (user supplied) function.
void thread_function(string &s){cout <<std::this_thread::get_id()<< "\n";}
std::thread t(&thread_function, s|std::ref(s));//s was passed by value (even &)|reference
t.join();

std::vector<std::thread> workers;
for (int i = 0; i < 5; i++) {
	auto t = std::thread([i](){cout << "thread: " << i << "\n";});//or auto t = std::thread(&task, i); calling void task(int i)
	workers.push_back(std::move(t));
	}
std::for_each(workers.begin(), workers.end(), [](std::thread &t){t.join();});

wraps a reference in a object reference_wrapper<T> is pass  by value std::ref(mvector); can be used an array which was not possible with T&,  for passing references to objects over to the new thread, rather than copying the objects
#include <thread> <mutex> <condition_variable><atomic>
thread t[num_threads];|vector<thread> th;
atomic<int> result(0);
for (int i = 0; i < num_threads; ++i) { t[i] = thread(func, i,std::ref(result)); | th.push_back(thread(func,i, std::ref(result)));}//void func(int tid,atomic<int> &result) //uncopyable but movable thread added to vector by move ctr as rvalue
for (int i = 0; i < num_threads; ++i) { t[i].join();     } | for(auto &t : th){   t.join();}

std::function store and pass a 'callable' object (simple function, functor and functions pointer, lambda expressions) with captured context variables like lambda while function ptr can not, but function has overhead vs function ptr not
int|void foo(double d) {}
int|void (*foo_ptr)(double) = &foo;//function ptr foo_ptr(5.0); foo same as &foo 
std::function<int|void(double)|decltype(foo)>|auto call_foo = &foo|[](double d){...}; //call_foo(5.0);

Matcher IsFive= Matcher(5);//Matcher IsFive(5); para constructor instance 
std::function<bool(int)> callfunctor(IsFive);//signature match the operator defined in previous functor 
if(callfunctor(10)){...

vector<function<void(double)|bool(int)>> fs;
fs.push_back(foo|IsFive);
for (auto& f : fs)  f(5);

std::bind  generates a new callable that �adapts� the parameter list of the original callable object.
std::function<void(double)> call_foo = std::bind(&foo,5.0)|(&foo,_1)//call_foo()|(5.0); 
auto call_add = bind(add, _1, 20, ref(result)); //f(80); to void add(int a, int b, int& r)

captured var can be used in lambda anonymous func []() mutable -> T { } , omit -> T if only 1 return stmt
[x, &y,this]: x is captured by value, y is captured by reference,all member of the class, [=|&]: any variable currently in scope is implicitly captured by value|reference, mutable allowed to change var captured by value, 
struct isEven{ bool operator()(int i) {return (i % 2) == 0; } };//functor
isEven ie; 
vector<int|T> vt.erase( std::remove_if(vt.begin(), vt.end(), ie | [](int i|T& t){return (i % 2) == 0;}), vt.end() );
vector<int>::iterator it =find_if(vt.begin(), vt.end(),ie);
int sum = 0;
auto ls = [&sum](int i) {sum += i; //return sum};//ls(1);ls(2); return 1 3, must auto because it is compiler-generated unknown type
for_each(vt.begin(), vt.end(),ls);

//pFoo is function pointer to a function take a int arg and return bool, allow a caller to �hook� it�s own function with same signature
bool (*pFoo)(int) = foo|goo;pFoo|(*pFoo)(n);//declare or assign then resign and call to bool foo|goo(int i){}
void SelectionSort(int *anArray, bool (*pComparison)(int, int))
{...if (pComparison|(*pComparison)(anArray[nCurrentIndex], anArray[nBestIndex])) 
                nBestIndex = nCurrentIndex;...}
int main()
{...SelectionSort(anArray, Descending);...}//bool (*pComparison)(int, int) = Descending; 
bool Ascending(int nX, int nY){return nY > nX;}
bool Descending(int nX, int nY){return nY < nX;}

function object( Functor) is a object which acts like a function. the class defines at least one operator().
class Matcher
{
   int target;
   public:
     Matcher(int m) : target(m) {} //initializer list
     bool operator()(int x) { return x == target;}
}
Matcher IsFive(5);//can hold state
if (IsFive(n)) { //() is operation

int t=5;
auto mc = [t](int i) {return i==t;};
mc(6);//false

C++11
shared ownership shared_ptr contains at least two pointers (to target object and control data for reference counting), twice as large as a basic unique_ptr (stateless deleter func does not add space, so = 4 bytes raw pointer).
shared_ptr<int> sp = make_shared<int>(5); //single memory allocation more efficient vs 2 memory allocations by sp(new int(5));
Raw addresses (including ordinary pointers) cannot be assigned directly to smart pointers. 
shared_ptr<int>   sp;
sp = new int(5);  // ERROR!
sp.reset(new int(5)); //OK
use_count( ) = reference count  or debugging watching the stong_ref, using atomic  thus threadsafe. atomic operations incur a little overhead and allocate a little extra memory to store the reference count (unless millions)

auto ptr = make_shared<MyClass>("obj1");
ptr->methodA(); someMethod(*ptr|ptr.get());//To get the resource associated with the shared_ptr.
shared_ptr<MyClass> anotherPtr = ptr; 
ptr.reset(new MyClass("obj2"); // now ptr switches to pointing to "obj2", but the "obj1" object is not deleted as anotherPtr is still holding it
anotherPtr.reset()|= nullptr; //de-attach, now no shared_ptr object is referencing the "obj1" MyClass*, so it is deleted

void main( )
{
 shared_ptr<int> sptr1( new int ); //sptr1.use_count( )=1
 *sptr1 = 5;
 shared_ptr<int> sptr2 = sptr1; //sptr1|2.use_count( )=2
}//use_count( ) =0  and sptr1 
void main( )
{
 int* p = new int;
 shared_ptr<int> sptr1( p);
 shared_ptr<int> sptr2( p );
}//sptr1 out scope, p is destroyed as use_count( )=0, when sptr2 out scope try to release the p mem has been destroyed > crash

    vector<shared_ptr <MyClass> > v;
    shared_ptr<MyClass> m(new MyClass);
    //The vector will add one reference to each added object
    v.push_back(m);
    //Every object now has 2 references
    m.reset(); //Object has 1 reference left
    v.erase(v.begin()); //Object has no reference left

template < typename T > class SP
{
private:
    T*    pData;       // pointer
    RC* reference; // Reference count

public:
    SP() : pData(0), reference(0) 
    {
        reference = new RC();
        reference->AddRef();
    }

    [explicit] SP(T* pValue) : pData(pValue), reference(0)//SP<string> s=new string("t"); [not] work as SP<string> s(new string("t"));
    {
        reference = new RC();
        reference->AddRef();
    }
    // Copy constructor: Copy the data and reference pointer (to the same count) and increment the reference count
    SP(const SP<T>& sp) : pData(sp.pData), reference(sp.reference)
    {
        //this is not existing instance so need not compare to &sp and release old data/ref like operator=
        reference->AddRef();
    }
    ~SP()
    {
        if(reference->Reset() == 0)
        {
            delete pData;
            delete reference;
        }
    }

    T& operator* ()    {        return *pData;    }

    T* operator-> ()    {        return pData;    }
    
    SP<T>& operator = (const SP<T>& sp)
    {
        if (this != &sp) 
        {
            // Decrement the old reference count if reference become zero delete the old data
            if(reference->Reset() == 0)
            {
                if(sp.pData!=pData) delete pData;
                delete reference;
            }
            // switch the data and reference pointer and increment the reference count
            pData = sp.pData;
            reference = sp.reference;
            reference->AddRef();
        }
        return *this;
    }
};

class RC
{
    private:
    int count; // Reference count

    public:
    void AddRef()
    {
        count++;
    }

    int Reset()
    {
        // Decrement the reference count and return the reference count.
        return --count;
    }
};

void main()
{
    SP<Person> p(new Person("Scott", 25));
    p->Display();//Display is method of class Person
    {
        SP<PERSON> q = p; //p and q point to the same person object and reference count 
        q->Display();  // Destructor of q will be called upon out of scope, the reference count decrement to 1
    }
    p->Display();
    // Destructor of p will be called upon out of scope, the reference count decrement to 0 and person pointer will be deleted
}

unique ownership unique_ptr replace auto_ptr plus support array unique_ptr<int[ ]> uptr( new int[5] ); 
unique_ptr in STL container by clean ownership - the container destroys pointers and pointers auto deallocate their objects, better than direct store object copy in container 
STL collections with move constructor defined std::vector<unique_ptr<MyClass>> v; v.emplace_back(new MyClass("hello world")); //pass arg to more unique_ptr ctr efficient than v.push_back(unique_ptr<MyClass>("hello world")); 

release() yields ownership of the managed object without deleting it(mem leak, not applicable to shared_ptr) whereas reset() destroys the resource.
unique_ptr<Foo> source() {return unique_ptr<Foo>(new Foo);}
void sink(unique_ptr<Foo> p) {  cerr << p.get()|->data;}
unique_ptr<Foo>|auto q = source(); //not auto*
sink(q);                    // ERROR! can't directly copy or assign unique_ptr, cleanly ownership transfer ensure only a single unique_ptr owns the pointed Foo instance 
sink(move(q));              // move OK, pmain is empty now. same as p=move(q), Foo instance will continue to live in sink{ } 

can�t store unique_ptr in cache, since the objects may get deleted > dangling pointers. instead cache keeps weak_ptr to objects without holding strong reference, weak_ptr to refer to a shared_ptr without actually owning it, access object only if still exist
    std::shared_ptr<int> sptr;
    sptr.reset( new int(10));
    std::weak_ptr<int> weak1 = sptr;
    sptr.reset( new int );
    *sptr = 5;
    std::weak_ptr<int> weak1|2 = sptr;
    if ( auto tmp = weak1.lock() )    { std::cout << *tmp << '\n';  }//weak2 5
    else    {        std::cout << "expired\n";    }//weak1 expired, will be dangling pointer if use raw/unique_ptr

avoid memory leak caused by cyclic reference (parent shared_ptr to children, child weak_ptr to parent instead of shared_ptr otherwise can  no longer be automatically freed, convert it temporarily to shared_ptr when it needs access to its parent.)
weak_ptr<Parent> parentWeakPtr_ = parentSharedPtr;//automatic conversion to weak from shared
shared_ptr<Parent> tempParentSharedPtr = parentWeakPtr_.lock(); //must be converted to std::shared_ptr in order to assume temporary ownership and access the referenced object.
if( tempParentSharedPtr ) {
  // acess parent via tempParentSharedPtr, will be released when it goes out of scope
} else {
  // parent already freed
}

class node {
 vector<unique_ptr<node>> children;
 node* parent;//(non-owning) raw pointer refer to an object that outlive this pointer, no need to delete it to deallocate the parent node.

[Old]
auto_ptr: avoid memory leaks, only one auto_ptr may own an object at a time, its destr delete the ptr ~auto_ptr() {delete ptr;}.
it won't avoid dangling ptr: after delete ptr; pointer still points to that memory location which maybe reallocatd to another process, if original process then dereferences it > unpredictable behavior  
auto_ptr owns the object that it holds a pointer to, and only one auto_ptr may own an object at a time
std::auto_ptr<Cls> p(new Cls(para));//same as Cls* ptr= new Cls(para); anto_ptr<Cls> p(ptr); 
std::auto_ptr<Cls> q = p;   // (auto p==null) p->func(): err, Copy constructor or assignment transfers the ownership of the object: auto_ptr (auto_ptr& src) or auto_ptr& operator= (auto_ptr& src) instead of (const auto_ptr& src)
auto_ptr passed to func by value = copy transfer the ownship to the arg ptr which gets deleted after the func scope
auto_ptr return to func also transfer the ownship to the return ptr in caller
copies of auto_ptrs are not equivalent, never safe to put auto_ptrs into standard containers

malloc/free() allocates/release memory for object in heap but doesn't invoke object's constructor/destructor and returns a void* pointer while new/delete do in free store, and type safe returns a mytype* pointer, also can be overloaded(operator),do NOT cross use:undefined behavior."operator new" works like malloc
delete pointer will do nothing if the pointer already set to NULL/0, otherwise calls the destructor of the pointer target object, then releases the memory that the pointer points to, does not delete the pointer itself! so afterward should set ptr=NULL / 0; C++ definition of NULL is 0 
delete[] array: int a[10] = { 1, 2 };|int* a = new int[10];delete[] a;//no effect, local auto dealloc| ok to new dynamic alloc//if delete a; only the first element (array name point to) destructor will be called and its mem will be released
realloc changes the size of the block of memory pointed to by the Pointer parameter to the number of bytes specified by the Size parameter and returns a new pointer to the block. 
void *malloc(size_t size); for single object, void *calloc(size_t nelem, size_t size); for number of element object each size (array)
realloc suit for resize/extend mem for big array, less costly than newly by malloc

typedef struct {size_t size;} Metadata;
void *my_malloc(size_t sz) {
    size_t size_with_header = sz + sizeof(Metadata);//prepend Metadata header to store actual memory size is allocated
    void* pointer = malloc(size_with_header);
    Metadata* header = (Metadata*)pointer;
    header->size = sz;   
    return pointer + sizeof(Metadata);//return the address of wanted size starting after the Metadata header
}
void my_free(void* ptr){
Metadata* header = (Metadata*)(ptr - sizeof(Metadata));//get actual allocated memory size to be freed by header->size
 
if constructor throws an exception allocated mem sizeof(mclass) will automagically be released
instance of an empty class allocated memory size=1 byte (compiler insert a char memory address to identify a class, methods do not allocate mem)
class A{char c;char h;int p;} //8 bytes: char 1,padding 2,int 4
class A{int *p; static int a; }//size of class: 4|8 bytes on 32|64bit compiler/system for the pointer, 0 for static var stored in seperate Global memory.
A derived class size = 4 bytes virtual table pointer  + non-static members + ALL base classes in chain 
void * memset ( void * ptr, int value, size_t num );Sets the first num bytes of the block of memory pointed by ptr to the value (if int, convert to unsigned char).
memset(&t|p, 0, sizeof t) should not be used on the objects of a class with virtual functions because the memory (begining) storing v pointer and data member gets overwritten.
memset(this, NULL, sizeof(classname)); should not used in constructor on a class : base {fields;//will be erased} 

function's signature = function's name, type and number and order of parameters, const-ness(diff by const|non-const objects), not return type. member func (overload) must have different signatures in a class 
in same class int A(int a){..} char A(int b){..}//compile err: ambigous declaration (same signature not overload),ret type & para name & by value|reference does not qualify sig 
c++ compiler uniquely rename overloading function based on parameter list (so each signature has unique mangled name), 
can not call mangled function name from c code unless disable name mangling by declaring the function as extern �C� void foo( );

overload operators as member function, implicit *this pointer points to current instance would be the left hand side parameter, unary|binary operator like */&() | +/==(&rhs) need none|one argument as right hand side parameter by const reference, as non-member function, must supply one|two arguments for unary|binary op (2 arg on both side of op like obj1 = 2 * obj2), operators that cannot be overloaded . (Member Access or Dot operator) ?: (Ternary or Conditional Operator )
class Cents
{public:
    friend Cents operator-(const Cents &cCents);// not a member function
    Cents operator-();// a member function};
Cents operator-(const Cents &cCents)//not a member function
{    return Cents(-cCents.m_nCents);}
Cents Cents::operator-()//a member function, unary operator (-5) as has no parameter
{    return Cents(-m_nCents);}

>> and << can only be overloaded as member functions, std::ostream & operator<<(std::ostream &os, const T &val), os|val is the left|right hand side parameter, cout << "test"
MyClass& MyClass::operator=(const MyClass &rhs)
{  if (this == &rhs)
     return *this;
   this->data = rhs.data;// The List STL template requires overloading operators =, == and <.
   return *this;
int|bool MyClass::operator==(const MyClass &rhs) const //change no state 
{  if( this->data != rhs.data) return 0;
   return 1;
const MyClass MyClass::operator+(const MyClass &other) const 
{    return MyClass(*this) += other;//return a copy of self, const for return temp object
int MyClass::operator<(const MyClass &rhs) const
{  if( this->data < rhs.data ) return 1;
   return 0;
ostream &operator<<(ostream &os, const MyClass &val)//or ofstream : fstream  (i|ofstream : In|output stream class to operate on files ) ->iostream (i|ostream In|output stream)
{  os << val.data << ' ' << val.id << endl;
   return os;
int MyArray::&operator[](int i)//const�T&�operator[](size_t�i)�const;//declare read-only�access:const
{  if( i > SIZE ){return arr[0];}
          return arr[i]; }

class A
{public:   int x;
protected:int y;
private:  int z;
};
class B: public A //public inheritance : IS-A inheritance
{public:
    B()
    {   x = 1; // okay: public
        y = 2; // okay: protected
        z = 3; // not okay: derived classes can't access private members in the base class A
    }
};
class C: protected A //protected inheritance : is-implemented-in-terms-of
{public:
    C()
    {
        x = 1; // okay: protected
        y = 2; // okay: protected
        z = 3; // not okay
    }
};
class D: private A //private inheritance (default): is-implemented-in-terms-of
{public:
    D()
    {
        x = 1; // okay: private
        y = 2; // okay: private
        z = 3; // not okay
    }
};
class E: public D
{public:
    E()
    {
        x = 1; // not okay: derived classes can't access private members in the base class D
        y = 2; // not okay
        z = 3; // not okay
    }
};
int main()
{
    B b;
    b.x = 1; // okay: public
    b.y = 2; // not okay: protected
    b.z = 3; // not okay: inaccessible
 
    C c;
    c.x = 1; // not okay: protected
    c.y = 2; // not okay: protected
    c.z = 3; // not okay: inaccessible
 
    D d;
    d.x = 1; // not okay: private
    d.y = 2; // not okay: private
    d.z = 3; // not okay: inaccessible

is-implemented-in-terms-of: D is not A, but every D uses its A in its implementation. using containment instead:
class D {
  private:   A a; //only can access a.x

containment flexible than private inheritance when used for a has-a relationship. class D can have more contained object than only A  by Containment not private inheritance. 
Private inheritance if
1) You need to access protected functions of the base class. can access a.y as well as a.x
2) You need to redefine virtual functions 
 
'virtual' instruct compiler not to static bind, intead dynamic bind based on actual object type at runtime with vtable lookup cost of performance.
nonvirtual f, the invoked method is the one of the pointer types at compile time. ((B *)c)->f(); // B::f() 
virtual f, the method invoked is the one of the actual object run time     ((B *)c)->f(); // C::f() 
class B  
{virtual void F() {//BF 
 virtual void F(int a) {//BFa 
class C : public B  
{virtual void F(){//CF 
//redefining inherited methods hides ALL base-class methods of the same name, regardless of the argument signature 
c.F() //CF  
c.F(1) //compile err : no function arguments match 
c.B::F(1) //BFa, force to call base func 

class A {int n;
public:	virtual void F(int no = 10) {
		n = no;
		cout << "A" << n;
class B : public A{int m;
public:	virtual void F(int no = 20) {
		m = no;
		cout << "B" << m;
int main() {
	B b;|B b = B(); //static allocate. B b(); [wrong, b declared as func return B]  B b = new B(); [wrong, new operator returns a pointer ]
	A a = b;//A/base copy ctr is called so B/sub extra member and polymorphysm are sliced off |A &a = b;|A *a = &b/new B();//implicit upcast (downcast need B *b = dynamic_cast<B*>(a))|dynamic allocate. 
	a.F();|a.F();|a->F();
        A10|B10|B10 //runtime resolution only on virtual func of dynamically allocated var,initialization of the default parameter are statically bind at the compile time. int no =10, (not for var init in ctr or init list)
	B *b = static_cast<B*>(a);//revert above implicit upcast
similar to
void e(A a){a.F();} void f(A* a){a->F();} void g(A& a){a.F();}
int main()
{B b;e(b);//A	         f(&b);//B	       g(b);//B

class A
class B : public A //B pointer can NOT be passed to foo
class C : public A //A pointer need explicit downcast to dynamic_cast<C*>(a) to pass to foo
class D : public C //D pointer(implicit upcast) can be passed to foo and should at least have all the C members,
static void foo(C * obj) 

Virtual functions use base class pointers/references to call proper version of methods in actual derived classes object determined at runtime.                     
compiler sets up exactly one virtual table (a static array) per super and derived class that has at least one virtual function at compile time, super and derived class each have own vtable, and shared by all their respective instances.
compiler also adds a virtual pointer as the first member (hidden) to the base class, that is inherited by derived classes.upon creating an object, 
constructor set the *_vptr of the instance to that class' v-table, which has function pointers to the latest/lowest implementation address, NULL pointer to pure virtual functions. so cannot have virtual constructors where virtual pointer being set.
so define mulitple virtual functions for a class will add just one address member (vpointer) to an object.

should never call virtual functions from base constructor/destructor: because derived have not been constructed yet, or already been destroyed.
the vpointer|table may not have been updated by the derived class constructor yet, might end  up calling base class implementations of those virtual functions 
when call a virtual function from a constructor or destructor, the compiler calls the instance of the virtual function defined for the class being constructed, if it is derived class then the derived constructor, which run after base constructor, has not been called and the derived class is not created yet. the vtable is not fully initialized until the most derived constructor executes
when call a virtual function from a base destructor which run after derived destructor, C++ calls the base class function because the derived class has already been destroyed

class B1 {
  void f() {}
  virtual void f1() {}
  int d1;
class B2 {
  virtual void f2() {}
class D :  B1, B2{
  void f2() {}
  int d2;
mem of instance B1:
  +0: pointer to virtual method table of B1 {+0: pointer-->B1::f1()}//non-virtual f() not included  
  +4: value of d1
mem of instance D:
  +0: pointer to virtual table of D for B1 {+0: pointer-->B1::f1()}//not overridden
  +4: value of d1
  +8: pointer to virtual table of D for B2 {+0: pointer-->D::f2()}//overridden
 +12: value of d2

derived class does NOT inherit base constructor/de and friends and assignment operator, but default constructor/de are always call in chain 
class sub : public sup {
  public: sub (int a) [: sup (a)] {this->sup::foo( );//no java.super in c++
all the constructor and assignment operator private to prevent class to be derived
public:	virtual void method() = 0;//one or more pure virtual function makes a class abstract: cannot be instantiated, any implement with the func name on the same class is ignored, enforce derived class must implement the func,  it can have implementation in base for derived to call B::f();. 
pure virtual function= abstract, to ensure that this function is overridden in derived classes, base class's func are all pure virtual func = interface (c#) 
class base{  public: virtual int foo(float x) = 0;};
class derived: public base{ public:int foo(int x) [override]{ }//[compiler error changing the type] warning hiding virtual method by same name
multiple inheritance: allow modeling of complex relationships but introduce ambiguity
multiple base methods have the same name: ambiguous compiler error unless explicit qualification sub.Base1::method();
Virtual Inheritance to solve diamond problem: a class multiply inherits from two classes which each inherit from a single base class. 
class base{virtual void foo();
class Base1 : public [virtual] base{ void foo();  
class Base2 : public [virtual] base{ void foo();
//compiler error ambiguous foo [sub has a single instance of the Base class]
class Sub : public base1, public base2 { void foo();//memory implement base1 after base2 with duplicate base [virtual pointer in vtable to single base]
virtual base class's constructors are always called ONCE from concrete sub class before any non-virtual base class's constructors.
dynamic_cast should be used for this to runtime validate relation

Polymophism provide mutilple implementations for same function call and select the correct implementation based on the calling context.
(a pointer to a derived class is type-compatible with a pointer to its base class, and specific type are auto resoloved at runtime,Base class object's pointer can invoke methods in derived class objects.)  
class A final{//seal class

#include <exception>
#include <stdexcept> invalid_argument runtime_error ...
using namespace std ;
class m_exception: public exception {
  virtual const char* what() const throw(){ return "mexception occurred";}
};
std::exception (inherit std::runtime_error) is defined in the <exception> header file under the namespace std.  virtual function what()can be overwritten to return the description
...
    catch (m_exception &error) { cerr << error.what() << endl; }//derived exception catch before base
    catch( exception &error ){cerr << error.what() << endl;}
    catch (...) {;}// catch-all handle
throw std::runtime_error(errorMessage);
throw; rethrow the same exception object from inner catch block to outer.
can throw any type like 20, and catch (int e) can catch by value,reference,pointer.
prefer throw by value try{ TestException ex; throw ex;} and catch by reference catch (TestException &error), when throw pointer the must catch pointer, if catch (client code) forget to delet the pointer, will memory leak  
try{throw new A[()];}catch (A *|& e) //ok|no: new returns a pointer, throw assign to catch same as TestException &error=ex;
throw exception by value, it is allocated on stack and then copied (copy constr) to a special memory location, the orig is auto deallocated (destr) upon out try{}, the copy will be catched and auto deallocated (destr) upon out catch{}
no finally instead use scope {} 

C++ Standard library throw exceptions derived from this std::exception class
bad_alloc thrown by new on allocation failure 
bad_cast thrown by dynamic_cast when fails with a referenced type 
bad_exception thrown when an exception type doesn't match any catch 
bad_typeid thrown by typeid 
ios_base::failure thrown by functions in the iostream library 

int myfunction (int param) [throw(ex1,ex2..)]; [no|certain exceptions allowed]

#include <typeinfo>
if (typeid(a) != typeid(b))//determine the same type at runtime.
Base|* a = sub|new Sub; //typeid(a|*a).name() == Sub 

src code>  preprocessor:substitution > compiler: assembly code>assembler: object code(.o) > linker > executable (.exe) 
preprocessor will substitutes #include <iostream> directive with library code cin, cout, cerr functions. 
Linker Errors:undefined reference to "foo" means function or library that is needed cannot be found
and marco #define NAME "string val"|numeric val for each occurance in the source code. 
#[el]if[n]def|defined if prev marco [not]defined #undef remove prev def, no duplicate definition 
  
include guards by marco to avoid dupplicate include thru multi .h >compiler error: multiple definitions 
// base_class.h , 
#ifndef BASE_CLASS_H//a unique macro name for each header file 
#define BASE_CLASS_H 
class base_class 
{  // some code}; 
#endif  
#include "base_class.h" 
 
#define MAX(a,b) (a > b ? a : b) 
inline int max(int a, int b) {return (a > b ? a: b);} 
templates is prefer over macro for type neutral code. 
 
#define DEBUG 1 
#if( DEBUG == 1 )//#expression handled as string 
#define ASSERT( expression )                         \ 
    cout << #expression << " ..." << num ;                \ 
    if( expression!= true) {                \ 
          cout << " Failed in file: " << __FILE__ ;       \ 
          cout << " at line: " << __LINE__ << endl;    \ 
    }                            \ 
    else cout << " Passed" << endl ;      
#elif( DEBUG == 0 ) 
#define ASSERT( result )                    \ 
cout << "Number is " << num << endl ; 
#endif 
#include <cassert>//or use standard macro
int main() 
{int num = 100 ;//substituted macro func can ref the same var   
 ASSERT( num < 100 ) ; 
output : num < 100 ...100 Fails in file: c:\assrt.cpp at line: 31 
Conditional compilation to comment out a block of code between #if and #endif

inline function : compiler will copy the entire function body every time to where the function is called. 
Advantages  eliminate function calling overhead.
Disadvantage changes inside inline function result in all calling location recompiled (unless LinkTimeOptimization Compilation):compile time dependency, comparing to ordinary function could just be linked. 
also larger code size can cause thrashing i.e. page thrashing, cache thrashing. Thrashing is a process where in more memory resources are used for preparing the execution rather than execution.
compiler won't take inline hint if the func has a variable argument list| resursion|loops |Calling another function| 
taking function addresses (called via the pointer to the function)|use different types of exception handling
class Math {                                
public: int addTwoIntegers(int a, int b);        
};
int Math::addTwoIntegers(int a, int b) { return a + b;}//normally define out of declaration
class Math {                                
public:  int addTwoIntegers(int a, int b) {return a + b; } // inlined function: including the code in the declaration

inline functions are usually preferable to macro functions 
1.Typechecking will take place in Inline but not in macro
2.Inline Text substitution will be done during compile time...but in macro pre-processor stage

http://www.yolinux.com/TUTORIALS/LinuxTutorialC++STL.html
Generic programming relies on polymorphism: template(compile time), virtual inheritance(run time)
template can be adapted to more than one type : generic, better performance and maintainability vs slower compile-times and poor compiler error messages/diagnostics, STL collections do lot of copying of objects.
template suite for function that took in any data type rather than limited type where overloading is better 
template <typename K,typename V> 
class mType {//class template/parameterized type: List<int> is a type (List) parameterized over another type (int). 
  private:
    K a; V b;
  public:
    mType (K, V);
    V& mFunc (K&, V&);
};
template <class K,class V>
mType<K,V>::mType(K A, V B) {
	a = A;
	b = B;
}
//templated function can be independent from <typename T> class, or use different type Q 
template <class T|Q>
T|Q& mType<T>::mFunc (T|Q& A, T|Q& B) {// or T& mFunc(T& A, T& B) within class, int r = mFunc<int>(1, 2);
  T|Q result;
...
  return (result);
}

//template specialization is to override the default template implementation without inheritance to handle a particular type in a different way.
template <>
class mType<char> {//replace all T with char:
template <> char& mType<char>::mFunc (char& A, char& B) { //or char& mFunc<char> (char& A, char& B)

template <typename T>
class MyQueue<T,double>{};//Partial Specialization vs <T,T>

template <class K, class V>
class PR{
K key;
V value;
public:
PR(K k,V v):key(k),value(v){}
};
template <>
class PR<int, string>{
int key;
string value;
public:
PR(int k,string v):key(k),value(v){}
};
    PR<int,int> pr(1,2);
    PR<int,string> prr(2,"b");//specialization

template <class T, class Q> class Derived : public Base<T> //Q as the templatized type for class Derived

int i=5, j=6, k;
myFunc<int> f(i,j); 
k=f.mFunc[<int>](i,j);
template suit for container, buildin data type (int,float) or third party library class/structure
templateS are compiled on demand, code is not compiled until a template is instantiated when required 
implementation of a template must be in the same file as its declaration.
unlike mormally the interface and implementation are IN separated files, interface generally consists of declarations in a "header file.h" 

#include <type_traits>
template <class T>
class A {
public:
  template<typename U = T>//template specialization without sparate class per each type
  typename std::enable_if<std::is_same<U,int|char>::value>::type//
  //typename std::enable_if<std::is_integral<T>::value, T>::type
  foo_int|char() {...}       
A<int> a;    a.foo_int();   // OK    // a.foo_char();  // error
std::is_polymorphic|is_base_of|is_class<MCls>::value
template<class T>
struct IsPolymorphic
{
    struct Derived : T {
    	virtual ~Derived();//add virtual pointer to Derived, if T has virtual pointer (Polymorphic) too then they have the same size 
    };
    enum  { value = sizeof(Derived)==sizeof(T) };  
};

Template arguments must be constants, specified at compile time, better optimisation, used where only constants (fxp an array's size) are allowed. Function arguments are variables, and don't have to be known at compile time.
[template<bool Mode>]
class Order
{bool Mode;
 public: 
  Order(bool OrderMode){Mode= OrderMode;}

Order ord(boolVar);//ok
[Order<true> ord();//ok Order<boolVar> ord();//err] 
same for template function template<int max> bool check(int in){if(in<max) return true; else return false;}//if(check<100>(i)) 

STL containers (http://www.cplusplus.com/reference/stl/) are not thread-safe 
sequence containers #include <vector|...|string>
vector is a dynamic array (auto de/allocate contiguous memory), allows random access to its elements via [i], and inserting (.push_back)and removing (.pop_back) elements from the end is generally fast.(STL string/wstring is a vector<char/wchar>). 
deque (�deck�) is a double-ended queue class, implemented as a dynamic array that can grow from both ends (push_back/front), not guaranteed to store in contiguous memory, elements not be access by offsetting pointers, keep information internally to direct access to element in constant time via [i]. 
list is a doubly linked list, only access to the start and end of the list, sequential access,Generally iterators are used to walk through the list. inserting and removing is very fast.

a vector allocates continuous memory, whereas a list doesn't, so vectors better in enumerate and random access, std::vector::size() is guaranteed to be O(1), whereas std::list::size() may be implemented O(n).
Size: the number of items currently in the vector, Capacity: how many items can be fit in the vector.Once full, adding new items will result in a new, larger (+32 default) block of memory being allocated and the existing items being copied to it
vector w;//0,0 w.push_back(1);//1,32
inserting and deleting only at the back (impl small stack) then choose vector.Inserting the middle of a vector of 1000 items would involve moving 500 items up one if not exceed capacity. Similarly with deleting. 
a vector use a single array reallocated for growth, the elements of a deque can be scattered in different chunks of storage so grow more efficiently (impl big stack) 
resize(num) insert or delete num of default contructed elements, push_back() call assignment since element already exist   
reserve() only allocates memory leaves it uninitialized. affects capacity() not size()

inserting and deleting in the middle (regularly) then use list.Lists are double-linked lists, so insertion at either end, or in the middle (providing you know an existing element in the middle) is equally fast. Also, splicing is fast (eg. putting a list into the middle of another) - all that does is re-arrange the end pointers. All of those operations would be slower with vectors, because you would need to copy everything.
inserting and deleting at the back and front then choose deque.
        	Retrieval	Insertion	Prepending	Appending	Deletion
List<T>        	O(n)         	O(1)		O(1)           	O(1)          	O(n)
Vector<T>    	O(1)           	O(n)          	O(n)        	Amort. O(1)	O(1)
r=std::accumulate(vect.begin ( ) , vect.end ( ) , 0 [,func])//sum of vector, 0 is init val, func such as int multiply(int x, int y){return x*y;}
STL containers hold actual objects rather than pointer to objects (value semantics) so add an element container copies it.

vector always encapsulate a dynamic array stored in the heap, while std::array encapsulate a statically-sized array, if init the class on the stack, the inner array will be allocated on the stack, avoid heap memory allocation overhead and fragmentation, suit small array (<100 elements), a typical stack is about 8MB, so allocate <= few KB or even less if recursive)

//std::begin return iterator on all containers vector<int> / arrays int v[], perfer over member functions vector<int>::iterator it = v.begin()
for (auto it = std::begin(v); it!=std::end(v); ++it){total += *i;}; only for array declared with size, not for incoming para array[] pointer unknown size
for( auto d : v ) { total += d;}

Associative contains automatically sort inputs when inserted
set stores unique elements, sorted set is balanced binary search tree. multiset allow duplicate elements.
std::set<int>::key|value_compare mycomp = myset.key|value_comp(); while ( mycomp(*(++it),*it) ){//set: keys = values keyvalue_comp() = value_comp()
return copy of set<T>'s comparison object, a function pointer or a function object/functor bool(T a,T b), By default less object = operator< of T.

bool(*fn_pt)(int,int) = fncomp;//bool fncomp (int a, int b) {return a<b;}
std::set<int,bool(*)(int,int)> myset (fn_pt);//function pointer

struct classcomp 
{ bool operator() (const int& a, const int& b) const {return a<b;}
};
std::set<int,classcomp> myset;//functor

map stores key/value pair. unique key (must be comparable, internally sorted by their key following the criterion specified by comparison object) for sorting and indexing, internal red black tree (balanced binary search trees) 
O(logN) insert/lookup, performance degrade as the key size increases.deleting |inserting element into a map does not invalidate any|iterators that point to existing elements. multimap (dictionary) allows duplicate keys (binary search trees). 
std::map <key_type, data_type, [comparison_function]>//the keys will be stored in sorted order : key_type must has the less-than operator(<) 

multiset<T>.begin|end() by  red-black tree slower than priority_queue<T>.top() by heap  

#include <map>
  std::pair<std::map<char,int>::iterator,bool> ret;
  ret = mymap.insert ( std::pair<char,int>('z',500) );//#include <utility> std::pair<char,int> p = std::make_pair ('z',500);
//single parameter insert return a pair.first point to either the newly created pair element or existing pair element with the same key
  if (ret.second==true|false) { //inserted|existed (ret.first->first|second == 'z'|200), mymap.at('z')==200 insert only create and fails if key exists

//map<int,int> already has an element with key 5 and value 0
m[5] = 10;                      // m[5] == 10, if exists modifies otherwise insert(make_pair)
m.insert(std::make_pair(5,15)); // m[5] == 10

auto f = map.find(1); 
if (f == map.end()) { 
  map.emplace(1, std::move(newObj)); 
} else { 
  std::swap(f->second, newObj); 
}
multiset and multimap, insert, emplace, and erase preserve the relative ordering of equivalent elements

std::map<char,int>::iterator it|itlow|up;//iterator is pointer
it = mymap.find('z');if( it != mymap.end() ) //it->second ==200
for (it = MyMap.begin(); it != MyMap.end(); ++it)
{if (it->second == value){break;}//lookup for value
std::map<char,int>::key|value_compare mycomp = mymap.key|value_comp();//Returns a copy of the comparison object used by the container to compare keys|values. 
it = mymap.begin(); char highest = mymap.rbegin()->first; | std::pair<char,int> highest = *mymap.rbegin();//last element
do {...  } while ( mycomp((*it++).first, highest) | mymap.value_comp()(*it++, highest) );//true if 1st element's key go before (less than) 2nd 
itlow|up=mymap.low|upper_bound ('b|d');//return an iterator to element with key b|e 
mymap.erase (it|itlow,itup);//remove b,c,d
map use less memory than unordered_map
unordered_set hashtable, unordered_map dictionary (internal linkedlists/vectors) stores key/value pair by applying hash function on a key, so values are not stored in sorted order. insert/loopkup can be done in O(1) time if no collisions. chaining or probing to avoid collision,hash is fastest for a big dataset
std::unordered_set<int> myset;
for ( auto it = myset.begin(); it != myset.end(); ++it){std::cout <<*it;
std::unordered_map<std::string,int>::const_iterator it = mymap.find (s);
std::cout <<it->first/second | (*it).first/second; 

std::tuple<int,char> foo (10,'x');//can contain diff types

Container adapters stack, queue, priority queue (auto sorted), can also adapt seq container : stack< vector<T> >

Allocators de|allocate memory for a STL container for future use, but not (yet) create objects therein. containers do not construct objects, they construct copies of objects: add/insert Copy object to element in container(class should be copy-able otherwise compiler error).list<const string|string * const> m; err: const not copyable/assignable 
It can allocate memory from a pool or directly from the heap, whichever you build the allocator from. By default std::allocator<>::allocate(size_type n, hint=0)|deallocate(pointer p, size_type n) using ::operator new|delete one or more times on heap, return A pointer (pass to deallocate arg) to the initial element in the block of storage and throws bad_alloc if it cannot allocate memory for n elements requested.
{    std::vector<MyObject> myVector;   ...} // out stack scope guaranteed that myVector object will be destructed and memory will be freed, for vector<*MyObject> only memory of pointer is freed not object, so need use smart pointer : unique_ptr by default and shared_ptr if needed vector<unique_ptr<MyObject>>  
or std::vector<MyObject> *myVector = new std::vector<int>; delete myVector; or std::unique_ptr<vector<MyObject>> myVector(new vector<MyObject>);
if container A = B;  All old objects in containerA are properly destroyed by destructor of objects, but the memory is not necessarily deallocated. A may reuse the memory for the objects that were copied from B rather than later allocating new memory, it like memory leak, can be adjust by shrink_to_fit 
A a; B b;//A:B
vector<A> v = { a, b };//b is copied and sliced as of A (losing extended members and polymorphic behavior).
vector<A*> v = { &a, &b}; vector<reference_wrapper<A>> v = { a, b}; //ok|vector<A&> v = { a, b}; err cannot reference types (const ptr not copyable/assignable) in a vector 

#multithreading 
inter-process communications have to be Signals, Pipes(FIFO), Sockets, message queues,semaphores,shared|mapped memory.
Context switching saving the state of the old process or thread and loading the state of the new one. several hundred may occurs per second, potentially add significant overhead to an execution.Switching the CPU between threads in the same process is typically faster than context switching between processes, 
Threads require less overhead to manage than processes, and intraprocess thread communication is less expensive than interprocess communication.

https://richardbarabe.wordpress.com/2014/02/21/java-deadlock-livelock-and-lock-starvation-examples/
Race Condition happens when a critical section  is not executed atomically
Deadlock threads waiting for each other to finish, No threads are changing their states 
livelocked thread A|B action is a response to the action of thread B|A,  they are not blocked but not progressing: busy responding to each other changing states .
Lock starvation occurs when a thread, having lesser priority than other ones, is constantly waiting for a lock, never able to take it because other thread(s) with higher priority are constanly aquiring the lock.
Priority inversion: tHigh is blocked on the critical resource that tLow is already in, so then tMed runs not in  the critical resource, tLow can not run until tMed blocks or ends, tHigh effectively being executed with a lower priority.
solution: the priority of tLow must be bumped up to be at least as high as tHigh so it wont wait on tMed

Semaphore (lock+signal count) up to a capacity of simultaneous access to a shared resource| same function,  
mutes (lock) only allows one thread into a controlled section,each thread may has different function and signal by condition variable, thread/process affinity, can be shared between processes. 
spin lock avoid expensive process re-scheduling or context switches but wasteful for long locking periods/critical section

fork() creates a child process by duplicating the stack of calling parent process. parent's other existing child threads is not copied to the new child process.
fork() returns twice if  successful . Once it returns 0 in the child process and then it returns child�s PID in the parent process.
    fork();//+1 c1 from orig fork();//+2 c23 from orig and c1 fork();//+4 c4567 from orig and c123 total 2^3  processes (7 child are created + orig) = 8 hello
    printf("hello\n");
exec() replaces the current process with a new program.

std::thread t( [](){ cout << std::this_thread::get_id();} );//thread constructor takes a callable object or function.
if (t.joinable()) { t.join();//blocking context thread till exe end of t}//A thread must be joined prior to the end of execution otherwise
undefined behavior. t.detach(); //background thread, A thread can only be joined|detached once, otherwise Terminate.
class ThreadRAII//RESOURCE ACQUISITION IS INITIALIZATION (RAII) ensure join() or detach() on exceptions
{   thread & m_thread;
    public: ThreadRAII(thread  & threadObj) : m_thread(threadObj) { }
            ~ThreadRAII(){if(m_thread.joinable())  m_thread.detach(); }
};
thread t(thread_func);   
ThreadRAII wrapperObj(t);
 
OR use std::packaged_task std::async instead of creating raw thread in production code
 
std::this_thread::yield()|sleep_for(std::chrono::milliseconds(30));
 
[implicit static] thread_local unsigned v = 0;//similar to "global" only "duration of thread" instead of "duration of entire program"
 
// Threads, like mutex and most other synchronization objects, are not copyable but movable
void by_lvalue(std::thread t) {}
void by_lvalue_ref(std::thread& t) {}
void by_rvalue_ref(std::thread&& t) {}
std::thread copy = t; // error
std::thread t2 = std::move(t);
by_lvalue(t2); // error
by_lvalue_ref(t2);
by_rvalue_ref(std::move(t2));

std::mutex m;//std::recursive|timed_mutex reentry by the same thread won't deadlock|try_lock_for(timeout)
std::condition_variable c;
thread_local int j = 0;// Each thread including main has its own copy 
void foo() { m.lock()//block till get if fail|if (m.try_lock())//return if fail|std::lock_guard<std::mutex> guard(m);  j++;  m.unlock(); }
std::lock_guard auto calls lock() on the mutex only once on construction (except adopt_lock as below) and auto unlock on destruction when out of scope unless manaually m.unlock, avoid mutex leak if exception thrown from the block : exception safety
similar std::unique_lock need for condition_variable, transfer unique ownership by uncopyable & movable can be returned from a function to hold lock across functions, small space speed overhead 
static mutex mtx;  
unique_lock<mutex> acquire_lock(){return unique_lock<mutex> mlk(mtx);} //returns rvalue
void release_lock(unique_lock<mutex> ml){ml.unlock();}//unique_lock<mutex>& can not rvalue unless const, but need change ml 

unique_lock<mutex> lk;
unique_lock<mutex> lk = acquire_lock()//(unique_lock& operator= (unique_lock&& x) takes rvalue|move(lvalue)
release_lock(move(lk)); //unique_lock (unique_lock&& x); no copy ctr so must move lvalue

unique_lock<mutex> lck(mtx,std::try_to_lock);
if (lck.owns_lock()){//if mtx was locked (or adopted) by lck
pass in contructor try_to_lock internally call mutex.try_lock, adopt|defer_lock do not lock on construction, manually unlock() before } and release() disassociates with the mutex without changing mutexs current state (locked or unlocked), try_lock_for(timeout) 
struct bank_account { int balance;mutex m;};
void transfer(bank_account &from, bank_account &to, int amount)
{   std::lock(from.m, to.m);//simultaneous lock (prevents deadlock)
    // make sure both already-locked mutexes by calling thread are unlocked at the end of scope
    lock_guard|unique_lock<mutex> lock1(from.m, adopt_lock);
    lock_guard|unique_lock<mutex> lock2(to.m, adopt_lock);
// equivalent approach:
//    unique_lock<mutex> lock1(from.m, defer_lock);//defer lock later
//    unique_lock<mutex> lock2(to.m, defer_lock);
//    std::lock(lock1, lock2);
 
    from.balance -= amount;
    to.balance += amount;
}
    std::thread t1(transfer, std::ref(my_account), std::ref(your_account), 10);
    std::thread t2(transfer, std::ref(your_account), std::ref(my_account), 5);

#include <condition_variable>
template <typename T>
class Queue
{
 public: 
  T pop()
  {
    std::unique_lock<std::mutex> mlock(mutex_);
    while (queue_.empty()) 
    {      not_empty.wait(mlock);//release the lock and block the thread till signaled, then acquire the lock and check if condition is met to continue else go wait    }
    //equivalent to cond_.wait(mlock, [this](){return !queue_.empty();});
    auto item = queue_.front();
    queue_.pop();
    return item;
  }
  void push(const T& item)|(T&& item)
  {
    std::unique_lock<std::mutex> mlock(mutex_);
    queue_.push(item|std::move(item));//rvalue para item treated as lvalue in func, move to rvalue reference T&& to benefit from move semantics.
    mlock.unlock();
    not_empty.notify_one();
  }
 
 private:
  std::queue<T> queue_;
  std::mutex mutex_;
  std::condition_variable not_empty;//similarly another condition_variable not_full to control MAX capacity
};

class lazy_init
{   [mutable] std::once_flag flag;//ensure only do_init once on same flag
    [mutable] std::shared_ptr<const expensive_data> data;
    void do_init() [const]    { data.reset(new expensive_data); }
public:
    std::shared_ptr<const expensive_data> get_data() [const]//only be destroyed if no one refer to it
    {   std::call_once(flag,&lazy_init::do_init,this);//like thread invoke member function: MCls mcls; thread(&MCls::func, &mcls[, args]);
        return data;
    }
};
std::call_once(flag, foo|[](){...;});//foo or closure/lambad will only be run once based on std::once_flag flag;

promise to set shared object by producer thread, associated future to retrieve it from consumer thread
1. std::future<int> ret = std::async([std::launch::any(default)|async|sync,] func,10, 0,);//called asynchronously on a new thread|called at the point of access to the shared state. 
2. std::packaged_task (movable not copable) wrapper put the return value or exception from the task into a promise as shared state, and asynchronously access via the corresponding future, augmented version of std::function 
std::packaged_task<int(int,int)> task(func); //int func (int x, int y){...retrun z;}  
std::future<int> ret = task.get_future(); 
std::thread th(std::move(task), 10, 0);//move lvalue to rvalue, or  task(10, 0);
...do something else...//return without waiting for the execution of func to complete.
int r = ret.get();//waits for the thread to finish r=z

3.void svc1|2(std::promise<int> &promObj)
{ int r = callsvc1|2();  
  promObj->set_value(r);
  ...do other stuff
}
    std::promise<int> promiseObj; //movable not copable
    std::future<int> futureObj = promiseObj.get_future();//std::promise object set_value() to its (only 1to1) corresponding std::future object on another thread
    std::thread t1|2(svc1|2, std::ref(promiseObj));
    std::cout<<futureObj.get()<<std::endl;//value can be available before threads call svc() are completed, and on whichever t1 t2 set first
futureObj.get() wait till  promiseObj.set_value(), will raise the mexception from promiseObj.set_exception(mexception), will raise a "broken promise" exception if promiseObj die without set

thr2=std::move(thr1); //thr2 becomes active, thr1 becomes "empty" or std::swap(thr,thr2);

#include <semaphore.h> 
int sem_init|destroy(&sem, 0, 1);//initializes a semaphore object pointed by sem, pshared is 0, the semaphore is local to the current process, otherwise cross processes (not supported by linux),The count associated with the semaphoreis  = 1 is binary sem only two 0/1 like mutex U/L. return 0 on success and -1 on error, in addition to writing an error code in errno 
int sem_post(&sem);//atomically increases the sem by 1. never blocks and can safely be used in asynchronous signal 
int sem_wait(&sem);//suspends the calling thread until the sem has non-zero count. then decreases sem by 1,always return 0. 
sem_trywait is a non-blocking  If the sem has non-zero count, then the count is atomically decreased and immediately returns 0. If the semaphore count is zero, sem_trywait 

CAS for atomicity
atomic<T> specialization for short int long longlong *anytype |++/fetch_add(1)||T old fetch_add(T new)/+=new internally compare_exchange| for general also char bool |T load()/=|=/store(T)|T old exchange(T new) internally compare_exchange |bool compare_exchange_strong|weak(expected old,desired new) always return true |maybe false on spurious failure when expected equal to the contained object, for non|looping(better perf) algorithms 
if (*this == expected) { *this = desired; return true; }
else { expected = *this; return false;} //next compare to this read
this_thread::get_id()
template <class T>//equivalent template func
bool atomic_compare_exchange_weak (volatile | atomic<T>* obj, T* expected, T val)
ABA problem: one thread made two reads from a mem both returns A, which fool the thread to assume 'nothing changed' in a CAS op, but another thread can change content of the memory location to B between the two reads then change the value back to A.
(If a node is removed from the lockfree list, then a new node is allocated to the same memory location due to optimization.)
double-length CAS (*p->32bit val+32bit counter), swap when both val and counter are same as old
auto garbage collection: the same mem wont be available immediately until collected and released by GC 
A wait free is a lock-free (guarantees system-wide progress ) with guaranteed per thread progress, operation completes finite steps. 

release-acquire for visibility 
memory reorder by both compiler (at compile time) and processor (at run time) to optimize while not modify the behavior as single-threaded, mostly cause problems in lock-free multithread still may lock up indefinitely without mutex fxp while (X == 0){ X = 1 - X;}, multi-thread write: CAS for atomic RMW, multi-processor:memory barrier http://preshing.com/20120612/an-introduction-to-lock-free-programming/
half(Acquire|release) fence: A memory barrier other reads & writes not to move before|after it, full fence (a+c)
as a compiler barrier, writes|Reads C++ non-relaxed atomic op & JAVA volatile creates release|acquire half-fences. lock creates full-fences on both boundaries (entry and exit)

release-acquire semantics establish happens-before|synchronized-with on the memory as C++ atomic store->load, Java|C# volatile (sequential consistency) write->read, mutex unlock->lock, thread start->join
If thread A|B atomic<T>.store|load(memory_order_release|acquire) and runtime A.store occur prior to B.load, onafter load thread B see everything thread A wrote to memory onbefore store. they are sync on value in the memory at that time. 

by default Sequentially consistent (,sync =memory_order_seq_cst) avoid race condition under multiple producer-multiple consumer,  generate memory fences after each store. to minimize fencing by specify other memory ordering requirements for each load and store, x86 already guarantees acquire|release for loads(read)|stores(write), so load|store(memory_order_acquire|release) produce no fences.
atomic<bool> ready = false; atomic<int> data = 0;
write thread: 	data.store(1, memory_order_release);
  		ready.store(true, memory_order_release);//in the current thread preceding writes(non|atomic) are not moved past the current atomic store or any subsequent stores.
read thread:  	if (ready.load(memory_order_acquire))//in the current thread subsequent reads(non|atomic) are not moved before the current load or any preceding loads. 
    		 cout<<data.load(memory_order_acquire);
memory_order_acq_rel: combines memory_order_acquire|release guarantees on loading/storing [compare_]exchange. produces a fence prevent move load before store in current thread
memory_order_consume: weaker memory_order_acquire, enforces current load before only other operations that are data-dependent on it, fxp subsequent dereference pointer won�t be moved before load of it 
memory_order_relaxed any reorder no sync, suit incrementing counters fetch_add(1, std::memory_order_relaxed) that only requires atomicity, but not ordering or synchronization

atomic<string|T*> ptr;int data; 
void producer()
{
    string* p  = new string("Hello");|T t;
    data = 1;
    ptr.store(p|&t, std::memory_order_release);//preceding writes will not reordered after store(), same order as source code, ensure their updated values by current thread are released to memory with atomic store 
    [data = 1;//maybe visible undefined]
}
void consumer()
{
    string* p;
    p = ptr.load(std::memory_order_acquire|consume);|T t=*ptr;
//subsequent reads will are not moved before load(), same order as source code, ensures updates by (not all) other threads are acquired from memory with atomic load
    assert(*p == "Hello");//always latest|always latest because *p carry dependncy of ptr, i.e. value obtained from the load are refreshed
    assert(data == 1); //always latest|maybe latest because data does not carry dependency from ptr
}

while (!flag.compare_exchange_strong(expected, 2, std::memory_order_acq_rel)) {   expected = 1;  }//other threads atomic<int> flag.load|store(memory_order_acquire|release)
all writes onbefore store with release from other threads are visible onafter compare|load(acquire) and exchange|store(release) is visible to other threads onafter load with acquire

atomic_thread_fence for multiple threads on a multicore more useful than  atomic_signal_fence for same thread or core
atomic_thread_fence(std::memory_order_release);//prevents all preceding writes from moving past all subsequent stores
m.store(1, std::memory_order_relaxed);
//m.store(1, std::memory_order_release);//prevents all preceding writes from moving past the store(release)
//r = m.load(std::memory_order_acquire);//prevents all subsequent reads from moving ahead the load(acquire)
r = m.load(std::memory_order_relaxed);
//can check r before call fence
atomic_thread_fence(std::memory_order_acquire);//prevents all subsequent reads from moving ahead all preceding stores

Within one thread memory accesses (reads|writes) to all volatile objects are guaranteed to not be reordered relative to each other (non-volatile memory accesses may reorder around volatile accesses), but not guaranteed cross thread, since volatile access does not establish inter-thread synchronization. volatile accesses are not atomic (concurrent read-modify-write race)

http://en.cppreference.com/w/cpp/language/eval_order
Evaluations:value computation + side effect(access/read|write to volatile object, modifiy/write to an object, calling a library I/O function)
within the same thread, sequenced-before relationship between evaluations means one complete before other but it does NOT prevent compiler/CPU reordering. indeterminately sequenced|unsequenced evaluations may be performed in any order |and may overlap
sequenced-before: comma(,) conditional operator (?:) logic operator (&& ||) full expression(;) initializer((),) controlling (for/while) conditional (if/switch)   
indeterminately sequenced: allocate(operator new) to the evaluation of  constructor arguments
unsequenced: potential undefined behavior (no error but unpredictable)
i = i++ + 1; // undefined behavior (but i = ++i + 1; is well-defined)
cout << i << i++;// undefined behavior (but cout << i << ++i; is well-defined)
f(++i, ++i); // undefined behavior (2nd ++i may run before 1st)

 function/expression have a side effect if it modifies some state affect outside execution environment. For example,  modify a global or static variable, modify arguments observed by caller, raise an exception, I/O data to a display or file, it make program's behaviour depend on history:the order of evaluation matters



#SOCKET 
http://www.tenouk.com/cnlinuxsockettutorials.html 
 
Every service/application/daemon/process will have their own port number that is unique (16 bit) within a machine/IP address. (telnet:23, http:80 http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xml  
a connection = server IP:port(1-1023) + client IP:port(1024-2^16) //IP:Port=socket, which is unique conmbination, data is deliver to dest host by IP and dest process by port num  
Linux, ports, protocols and service names are specified in /etc/services. 
 
IP4 address (2^32 0-31bit):  
network(domain) + host(device/subnet)       network size (larger=more host bits) 
0[1-7 bit]        [8-31 bit]         1-127. Class A (Large) 
10[2-15 bit]      [16-31 bit]        128-191. Class B (Medium) 
110[3-23 bit]     [24-31 bit]        192-223. Class C (Small) 
IPv6 have 128 bit addresses 
 
Ethernet address (Media Access Control or physical address) hard coded into the NetInfCard by the manufacturer,  
6 bytes shown as 6 hex delimited by : ipconfig (windows) ifconfig(linux) to view 
www.domain.com <DomainNameSys Unix/Linux:BIND Windows:DNS> IP address <Address Resolution Protocol> MAC address 
 
osi layer:                                     TCP/IP stack: 
app,prsnt(frmat, encrpt),session :stream(TCP) msgs(UDP)                HTTP,SimpMailTP,FTP,Telnet(rmt login),rlogin(rmtlogin unix),RPC,NFS(ntwk file),TrivialFileTP(booting),SimNetMgtP 
transportation (end2end un/reliable deliver): segments(TCP) packets(UDP)    TCP(transmit ctrl prtcl) UDP(usr datagram prtcl) 
network/internet (def datagram & hdl routing):datagrams                IP(intnet prtcl) 
physical/datalink/netwk acess (trans bin, fram & err chk):frames        hrdwr intfc(ethernet,token ring,X.25.wireless) 
 
IP packets= header + data, on send: Each layer places its own header in front of data it receives from previous layer(encapsulation MAC hdr|IP hdr|TCP hdr|data). receive is reverse.  
Datagram is a packet format defined by Internet Protocol.  if the Destination IP Address in local network, the packet is delivered directly to the destination; otherwise the packet is passed to a gateway/router for delivery.  
ICMP header 1X32 bits (Type, Code...) 
IP header 6X32 bits (Src/Dest Address,Protocol,Type of Service... http://www.tenouk.com/Module42.html) 
UDP header 2X32 bits (Src/Dest port,UDP checksum) 
TCP header 3X32 bits (Src/Dest Address,prtcl) 
TCP segment header 6X32 bits (Src/Dest port, seq/ack num, ctrl bits(SYNC|ACK|FIN),window... http://www.tenouk.com/Module42a.html) 
 
Internet Control Message Protocol header: 
Flow control: When datagrams arrive too fast for processing, the destination host or intermediate gateway sends an ICMP Source Quench Message back to the sender.  This tells the source to temporarily stop sending datagrams. 
Detecting unreachable destinations: If the unreachable destination is a host|port, the intermediate gateway|destination host sends the message. 
Redirecting routes: A gateway sends Redirect Message to tell a host to use another gateway 
Checking remote hosts: A host can send the Echo Message to see if a remote system's internet protocol is up and operational. When a system receives an echo message(hdr frmt;http://www.tenouk.com/Module43.html), it sends the same packet back to the source host (e.g. PING command). 
 
TCP and UDP built on top of the IP protocol. 
UDP(NFS,SNMP,RPC,TFTP) datagram socket: Connectionless (1 way Connection Reliable 1 shot deal), sent by Packets individually,Unreliable(no gurant, error checking but no recovery for lost packets, either whole packet or none is delivered from sender to receiver),
low-overhead,no sequence/ordering/ack, stateless, no handshake to init conn. suit for repeat broadcast 

Unlike TCP, UDP protocol does not have built-in flow-control capabilities, so if you can't process all of the received packets fast enough, kernel will start to drop new incoming packets because of the socket receive buffer is full.
$ netstat -anus
Udp:
    531412134 packets received
    125 packets to unknown port received.//without firewall, send udp packets to unlistend port
    38491 packet receive errors//doesn't include the problems occured on network card level, it shows only received packets on udp protocol stack, udp packet header corruption/ checksum problems or packet receive buffer size
    531247364 packets sent
http://fasterdata.es.net/host-tuning/
//increase socket receive buffer (default 32-128 KB per socket) to 2 MB's handle up to 1 Gbps of data, can upto 128 MB 
int size = 2 * 1024 * 1024; setsockopt(socket, SOL_SOCKET, SO_RCV|SNDBUF, &size, (socklen_t)sizeof(int));
$ sudo sysctl -w net.core.r|Wmem_max=33554432 //accordingly increase maximum value (default 131071) defined in kernel on /proc/sys/net/core/r|wmem_max receive|send
$ sudo sysctl -w net.core.netdev_max_backlog=2000 //optional increase number (Default 1000) of packet queued in backlog on kernel network card : 
 
TCP(FTP, telnet, http, SMTP) stream socket: connection-oriented(est end2end conn)(sender single msg maybe received in sequential/ordered packets), reliable(gurant dtgrm deliv, 2 way Connection Reliable), transparent byte-stream (no msg boundary). error detection (slower) and correction (pstv|ngtv msg|ack), sequence and segment large block,  and enables hosts to maintain multiple, simultaneous connections.  
Each seg contains a checksum for recipient to verify that the data is undamaged.  If undamaged, a positive ack.  If damaged, discards seg, and ngtv ack.  reliable delivery :upon ngtv ack or after time-out (packets lost on trans), sender reTansmits any packets without positive ack received. 
establish conn>three-way handshake(3 packets exchanged): clnt send SYNC seg, svr return SYNC-ACK seg, clnt reply ACK seg 
terminate conn>4 packets exchanged:clnt send FIN seg, svr enter CLOSE_WAIT state upon recv, send ACK and enter LAST_ACK state, clnt TIME_WAIT state upon recv then send ACK   
app<datastream>TCP<segments>IP<datagram>netwrkaccess<bits>-transmit 
init pakt upon conn always seq=0 at 1st bit, ack tells sender how many bytes has, the next send seq num = prev recv ack +1, Window(16bits)<=recv buffer-recved bytes: The number of bytes that can be sent before the data should be acknowledged with an ACK before sending more segments. 

Flow control ensure that the transmission rate of the sender do not exceed the capacity of the receiver. if exceed and no receiver buffer space left to store arriving packets, they are discarded, Bandwidth:1000 Mbit/s (1Gbps) packet loss:25%  Round-Trip Time (RTT):60 millisecond
netstat -s to see if a lot of TCP retransmissions indicate network congestion, Network Diagnostic Tool (NDT) nice tool to detect congestion problems
$ sudo sysctl -w net.ipv4.tcp_r|wmem = 4096 87380 16777216 //increase Linux 2.6+ autotuning TCP buffer min, default, and maximum limit, 
$ sudo sysctl -w net.ipv4.tcp_congestion_control=cubic|htcp|bic Binary Increase Congestion control

receiver sends out receiving window sizes (free bytes in the receiver buffer) to the sender, the number of bytes the sender can send without needing an ack from the receiver.

bind() failed 'Address already in use' when connect to TCP socket even after closed previous process using it: becuase connection can stay in
TIME-WAIT state for a minute, TIME-WAIT is to prevent delayed packets from previous connection being accepted by next connection, SO_REUSEADDR
socket option enfore kernel go ahead and reuse it anyway even port is busy in the TIME_WAIT state, $ netstat -anpt | grep 8140 check port status
 
/usr/include/sys/sockets.h which incld /usr/include/bits/socket.h :enum __socket_type {SOCK_STREAM = 1,SOCK_DGRAM = 2, 
when listening from a client asynchronous sockets don't block other client, a separate thread (at the OS level) listens on the socket and will invoke a callback function (specified when the async listening was init) when a socket event occurs. This callback function in turn will respond and process that socket event.  

http://uva.ulb.ac.be/cit_courseware/unix/part3_2.htm
#include <sys/types.h><sys/socket.h><netinet/in.h><arpa/inet.h>
struct sockaddr_in client, server;char buf[32];
-socket(int domain, int type, int protocol) returns a file descriptor for the socket (to be used by connect()) and -1 on error. 
-int s = socket(AF_INET, SOCK_DGRAM, 0);//system call:-1 on error 
-server.sin_family|port|addr.s_addr = AF_INET|800//0 use any available|inet_addr("156.59.20.50");
 
connect(int fd, struct sockaddr *remote_host, socklen_t addr_length) client Connects a socket (described by file descriptor fd to a remote host. 
Returns 0 on success and -1 on error. 
 
bind(int fd, struct sockaddr *local_addr, socklen_t addr_length) Binds a socket to a local address so it can listen for incoming connections. 
Returns 0 on success and -1 on error. server only 
-bind(s, &server, sizeof( server ))
 
listen(int fd, int backlog_queue_size) tells the bound socket to listen for incoming connections, and a subsequent accept() call actually accepts an incoming connection. The listen() function places all incoming connections into a backlog queue until an accept() call accepts the connections. 
Returns 0 on success and -1 on error. server only 
 
accept(int fd, struct sockaddr *remote_host, socklen_t addr_length) The address information from the remote host is written into the remote_host structure and the actual size of the address structure is written into *addr_length.the original socket file descriptor can continue to be used for accepting new connections, while the new socket file descriptor is used for communicating with the connected client. 
returns a new socket file descriptor to identify the connected socket or -1 on error. server only 

send/write(int fd, void *buffer, size_t n, int flags)Sends n bytes from *buffer to socket fd. 
Returns the number of bytes sent or -1 on error.
-sendto(s, buf, sizeof(buf)+1, 0, &server, sizeof(server));  

receive/read(int fd, void *buffer, size_t n, int flags)Reveives n bytes from socket fd into *buffer. 
Returns the number of bytes received or -1 on error. 
-recvfrom( s, buf, sizeof(buf), 0, (struct sockaddr *) &client, &client_address_size)

-close(s);

By default, TCP sockets are in "blocking" mode. connection "blocks" until the operation is complete like when you call recv() to read from a stream, control isn't returned to your program until at least one byte of data is read from the remote site.
"non-blocking" mode: recv()|send() return|puts data to the system buffer for that socket without waiting, if buffer is empty|full, the system will return immediately "Operation Would Block!"
int x;x=fcntl(s,F_GETFL,0);fcntl(s,F_SETFL,x | O_NONBLOCK);//reset socket descriptor to O_NONBLOCK

linux socket err /usr/include/asm/errno.h  ETIMEDOUT EPIPE
write(..) on a socket that has been closed at the other end will cause a SIGPIPE.
read on a remotely closed socket will return 0 (EOF) or ECONNRESET in some cases.
read(..) or write(..) on a socket that was never connected will return ENOTCONN.
read(..) or write(..) on a locally closed socket will return EBADF

http://tldp.org/HOWTO/Multicast-HOWTO-6.html, broadcast|multicast packet send all|joined hosts in the network recognize and read it
multicast traffic is handled at the transport layer with UDP, vs TCP provides point-to-point connections
FH_STATUS fh_mcast_XXX 
{setsockopt(socket, IPPROTO_IP, IP_MULTICAST_TTL|IF|LOOP|IP_ADD|DROP_MEMBERSHIP, &optval, sizeof(optval))//socket must be of the family AF_INET and type either SOCK_DGRAM or SOCK_RAW, level will always be IPPROTO_IP (IP layer)
LOOP optval: 1 enable, 0 disable (default)loop data generated by
 this host but also listened to
TTL optval: 0 - 255 time/hop to live, Routers decrement datagram's TTL when traverses from one network to another until 0 then drop, default 1 within same subnet (no router forward), <32 within same site/org
IF optval: overide default interface (INADDR_ANY) multicast datagrams should be sent from
ADD|DROP optval: struct ip_mreq optval; can join multi groups(< IP_MAX_MEMBERSHIPS 20) to the same socket, or multi interfaces in the same group 
/usr/include/linux/in.h //#include <netinet/in.h>
struct ip_mreq 
{
        struct in_addr imr_multiaddr;   /* IP multicast address of group to join */
        struct in_addr imr_interface;   /* local IP address of interface of the group, INADDR_ANY kernel auto choose*/
};

Nagle algorithm allows only one small segment to be outstanding at a time without an acknowledgment (ACK). If more small segments are generated while awaiting the ACK for the first one, these segments are auto concatenated into one larger segment. 
increases the efficiency of a network application system by decreasing the number of packets
setsockopt( sock, TCP_NODELAY,...) disable the Nagle algorithm to provide communication closer to real-time, at a cost of transmitting more frames and their associated headers.

cat /proc/sys/fs/file-max maximum number (>10,000) of file descriptors (socket) total allowed to be opened simultaneously
Two processes cannot bind to the same port at the same time, unless AF__UNIX sockets (inter-process sockets).  

#Linux  (Mint (same repo) on Ubuntu (diff repo) on Debian, RHEL(pay)+CentOS(free) on Fedora)
https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Deployment_Guide/index.html
http://www.tecmint.com/things-to-do-after-minimal-rhel-centos-7-installation/
 
each Linux distribution hosts their own software repositories contain software packages specially compiled for that distribution and version,
add new repo definition besides default linux dist repo, yum-config-manager [--endisable example\*] --add-repo http://www.example.com/example.repo  
or wget -O etc/yum.repos.d/example.repo http://www.example.com/example.repo, (rhel: etc/yum.conf | yum.repos.d/*.repo 
Ubuntu:/etc/apt/sources.list | sources.list.d/*.list)
package manager automatically download install appropriate package  or update from its configured software repositories, keep track of which files belong to which packages for uninstall and dependency
yum|apt-get install|remove pkg (from repo), dpkg|rpm -i pkg.DEB|RPM (downloaded file) on Debian/Ubuntu | Fedora/Red Hat
 
/bin (Essential in single user mode: su maintaince)/at awk->gawk bash sh cat chmod|grp|own cp date df echo env find grep gunzip-gzip(un-compress gzip file [>file2.gz]) hostname kill ln ls mailx mkdir mv un|mount netstat ping ps pstree (show process in hierarchy) pwd(show cur working dir)  rpm rm[dir] (-rf|-i dir : enforce|prompt recursive del on unempty dir) sed sort su systemctl tar taskset touch top (real-time cpu, mem, process: top -p pid) uname[-a](linux version)
 
/boot/vmlinuz(Linux Kernel file) grub
 
/dev/hda|c(HDD|CD) ramX port loopX sdaX(disc) ttyX (tel-terminal)
 
/home/cusr  [cusr@hostname ~] /|~ absolute root|user's home dir, /root[/] for root usr , cursor #root vs $user
 
/lib/cpp->/usr/bin/cpp -v(list all include dir)  ld-linux.so (dynamic linker) lib-glib.so (core c lib) libgthread.so lib-gcc.so upstart
 
/etc/cron[tab(schedule table)][.deny|allow(un|auth usr to cron)[.weekly|daily] inittab| init.d/->rc.d/init.d/   *|init|resolv(DNS)|sysctl.conf environment|profile(defaultscontext for su export PATH=""/bin:/sbin") host group/passwd|g/shadow grp/usr accts info(echo $SHELL|PATH default:/bin/bash|/[usr/local]/s|bin)|encrypt pwd logrotate.d/
 
/lost+found(recovering files)  /opt(non-linux-distribution packages like Java) /media/cdrom(Temp mount dir for removable devices)  /mnt(Temp mount dir)   /tmp (usr|sys temp files delete on reboot)
 
/proc/cpu|meminfo bus[pci] filesystems locks(Files locked by kernel) interrupts ioports(address) modules(loaded kernel modules) mounts(includeexternal file sys like HD CD) scsi stat swap(swap space) version(os,gcc) tty
     /net(network)/ip|6 packet protocols rout sockstat stat tcp udp wireless
     /sys/dev(dcrom scsi) kernel vm(virtual mem)    
     /<pid>(owner accessible)/status(state|u/gid mem_allowed threads of the process) cmdline environ(env vars) fd(file descriptors) cwd->current working dir of the process exe->the executable of the process
 
/sys(newer and more structured version of proc)/bus(isa|pci|scsi/dev|drivers)|block|class(by block|type) are links to devices(physical) firmware(memmap) fs/ext4/sda1|2 kernel module(loaded module & comp)/<device>/parameters power
 
/sbin (Essential sys binaries for su)/dump/restore(backup/restore) dhclient [-v verbose info] -r| (release|getnew) [eth0|wlan0] //DHCP Client renew IP  fdisk  fsck->e2fsck |xfs_repair (filesystem checks and repairs for ext234|xfs)  grub-install mkfs  grub(boot loader) ifconfig (network interface) replaced by ip  iptable  init->upstart lv|pv|vgcreate->lvm(logical vol mgr)  nmcli(NetworkManager)  [d]mraid mdadm(RAID)   reboot|shutdown->/lib/upstart/reboot|shutdown  restart|reload->initctl(sevice/job) sysctl
 
/usr/bin (Non-essential in single user mode, main dir for linux distribution-managed exes, upgrade by future distribution)/awk ar cpp du diff free gcc gdb gzip->../../bin/gzip kill->../../bin/kill ldd lftp man <cmd> (manual page: documentation) passwd [user](change pwd)  rpmquery|sign->/bin/rpm  scp ssh[usr@]server mysql python head/tail +|-n 5 [-f] XX.log (first/last 5 line [follow realtime])  sudo  tc(traffic ctrl) tee(ls >| tee [�a] file //output to screen | and file )  tmpwatch->usr/sbin/tmpwatch 30d /tmp/(can be scheduled in  cron to cleanup /tmp directory files that haven�t been accessed for at least 30 days)  top vim io|if|mp|pid|vmstat watch [-d] -n 1 free(run per 1 sec [hilite changefree cmd that output mem stat)  wget which whoami whereis  yum
    /include(C #include files)    /lib(.so for compile & lib for /usr/s|bin)
    /local(same subdir as /usr, nondistribution-managed installed locally, not be changed by future distribution )  
    /sbin(Non-essential sys binaries for su admin)/atd|crond(schedule task onetime|recur) apachectl (re)start|stop|status httpd  chroot (creat virtual sub system isolated from main OS)  group|useradd|del|mod(on etc/group|passwd) lsof sendmail logrotate  sshd(OpenSSH Daemon)|sssd(System Security Services Daemon to ID Auth provider like Active Directory by map linux UID to  SID),
 
/var(size variable data)/log(syslog audit.log)/lastlog(last boot) mail(email) cache(app cached data) lock(.lock files indicate a resource (database/file/device) already in use, not accessible by other process) run(.pid files of running process) spool(print|mail queue|abrt) tmp(temp files across reboots) wtmp(login/duration of each user)
 
/srv/msvc/(data for msvc)
 
[..]/home | [./]home is absolute|relative dir can|not be entered from any current working dir
source /etc/profile after change perm or export PATH=$PATH:newpath temp reboot
TAB prompt commands that begin with inputted letters, cmd -inputarg [val]  --queryarg
Unix Shells: Bash, Ksh is a program interface interprets commands from user to execute in OS
 System | Library calls (functions provided by the kernel|within program libraries) chmod|printf
ctrl-C|Z to abort/exit current cmd, ctrl-shift-c|v copy|paste in terminal/vim
 
library is a package of code to be reused: header files(/usr/[local]/include) +  precompiled binarys (/lib, /usr/[local]/lib )dynamic libraries better than static libraries
static library (archive) (libXXXX.a ): are statically linked and copied into each executable upon compile, so executable can be distributed independently, but wasted space and hard to upgrade: the entire executable needs to be replaced.
Dynamic (shared) library (libXXXX.[s]o) : shared by multiple executables by being loaded into memory/cache once at run time, saves space. can be upgraded without replacing executables
 
[none], .bin(rare) | .exe                 | Linux executables
.sh                | .bat                 | Shell script // bash *.sh to run,
.deb  .rpm         | .msi                 | Installer package for linux releases
.tar.gz .tgz .tar .gz | .zip                 | Compressed files that can contain a program or any other data, like images, documents, etc
.ko                | .sys                 | Drivers and kernel modules are loaded into the Linux kernel and have more hardware access
 
$$ the current process id.
$? numeric exit status the latest command. By convention, exit 0 =success; other= error (1 general)
some command
ret=$?
if [ $ret -ne 0 ]; then
    echo "failed with exit code $ret"
fi
exit $ret
 
awk '{ if($2 == "t4") && ( $3 > 2 ) print $1;}' input_file //$i column in a row
$ awk '$4 ~/Technology/' employee.txt //~  matches regular expressions  print whole line
awk 'BEGIN {sum=0} {sum+=$5} END {print sum}' input_file
awk 'BEGIN { for(i=1;i<=5;i++) print "square of", i, "is",i*i; }'
awk 'BEGIN {FS|OFS=":"} {print $2}' input_file //set in|output delimmiter : instead of default space
awk '{print NF|NR}' input_file  //number of fields|records
awk '{  split($2,arr,","); // substr($2,3) length($2) index(string,"S") sub("S", "B", $2)//replace S with B
        if(arr[3] == "UNIX")
        print $0
} ' file.txt
 
ar -t|x[cr|d|r] mylib.a [myClass.o]//list|extract[create|delete|replace(add)] all object files *.o |[provided .o] in the static library (archive file)
cat f.txt [-n] |less //create new file, or open existing file [with line num]  f1>|>>f2 overwrite|append to f2, touch [-c]  file //[re]create a empty file
source mylib.sh //include in current bash context
 
diff  file1,file2 //compare by line [-c(divided)|u(merged)|y(sidebyside)] !+-<|> lines from file1|2 change|add|del|move to sync  [-b|B ]ignore 
blank space|line
diff dir1 dir2 //list items only in one of them 
cmp //compare by byte, return fist diff byte/char and line num
 
usr/bin/ du -a [dir|file] //size of all in cur[spec]dir|file
bin/df [ -h | sort �h]  //list disc partitions for /dev/sdxi of each mount point( / home tmp var var/log ..) | hard drive sorted by size
 
find /|.  -[i]name *.txt | ".*" //root|cur dir case [in]sensitive txt|hidden files -perm 0777 | /u=r | /a=x files has permission 777 | readonly | executable, list perm denied dirs that can not be searched
find /tmp -size +50M|k|c -size -100M [-exec rm -f {} \;] //del file size btw 50MB|KB|Byte � 100
find ~|. [-type f|d] [-user|group owner] -c|m|atime/min �[+]5 [-delete] //[delete] all file(incl subdir)/dir of home|cur dir changed(prop)|modified(content)/accessed 
in[before] last 5 days/mins
find ./sub -max|mindepth 2  -not -name 'abc*' [-o] ! -iname "*.php" //multi cond AND [OR] Invert(-not=!) to|from 2 level under cur/sub dir 
(default all levels)
du -h [/path] | sort -h [-r] //size of sub in human readable format, sorted/reverse
 
p|zpgrep on process|zip; home|~]grep -r[n] "int" richardqluo|.[/] //recursive dir [line num]; grep -l 'int' *.* //list file name in cur dir
f|grep [-C 3] -i[w][c][v] richluo /etc/passwd //[show 3 line around match] [exactword][count][notcontain];  = cat /etc/passwd | grep -i richluo
shell pipe output of prev cmd to input next cmd without temporary file readcmd < input.data | proccmd | writecmd > output.data
Fixed grep (Fgrepor grep -F) faster for searching whole string vs extended grep (Egrep or grep -E) using extend regular expression ^...
 
ls -l[S[r]] | [less] grep ^-/d //list file/dir [sort by size/reverse] [by scroll], l/p/s symbolic link/pipe/socket file
mkdir [-m775] <dir>
d|-|l rwx rwx r-x owner group //dir|file|link perm: read write access(dir)|execute(file) to curusr/group,  read nowrite access|execute to other
??? curusr has no read(r)|access(x) to the file|dir 
chmod u=rwx,g=rx,o=r myfile //4 read/r 2 write/w 1 exe/x 0 none, rwx=7 , chmod go=rw <dir> //drwxrw-rw-
chmod u-rx, g+x,o|a+w [--reference=file1] file  //remove read & exe from user(owner), add exe|write to user's group|other/all(user group other), 
same perm as file1
chmod -R 755 dir/ //recusively to all under dir
chgrp|own <grp|usr> <file|dir>
 
Set-user|group ID perm //The process act as the owner (rather than the user running) of the file
-r-sr-sr-x   1 root sys //perm of /usr/bin/passwd, passwd command process execute as its owner|group(root) instead of the non-root user who 
running it to change his password by update /etc/passwd|shadow without write permission.
chmod u|g+s file/dir //SGID apply to a dir then sub dirs and files will be created with same owning group of dir regardless created by who
-rw- > chmod u+s > -rwS > chmod u+x > -rws //chmod 46|7XX <file> S|s not|grant execute permissions to the owner
r-x|- chmod +t dir //sticky bit prevent delete/modify file in shared dir (like /tmp) other than owner, r-t|T other not|have access to dir
 
ln [-s] myfile.txt my-hard[soft]-link //moving myfile.txt will not affect the hard link as it links to the underlying inode just like new name to a file, Symlinks, unlike hard links, can cross filesystems, can point to directories relative or absolute
 
/bin/mailx > /usr/sbin/sendmail >SMTP
[echo "body" (cmd output to mail)|] mail -s "subject" [-aFrom:sender@abc.com] rcvr@abc.com,rcvr2@abc.com [-c rcvr3@abc.com] [<body.txt]
yum install mutt //to attach file
mutt -s "Subject" -a /path/to/attachfile -- rcvr@abc.com < home/user/body.txt
 
usr/bin/pam* //Pluggable Authentication Modules for auth acct pwd session
ldd /bin/login | grep libpam //libpam* used by login /lib/libpam.so
 
ps -A (display all runing process) -u XXX (process by user XXX) -eLf (every process+light weight process (thread)+fullinfo)
ps -T |top -H -p <pid> :view threads of a process on Linux
ps -el | grep 'procname' or 'Z' //S : sleeping R : running D : waiting T : suspende Z : zombie
zombie|defunct process is a process that has been completely deallocated but still exists in the process table until parent process reap(calls wait())on it or parent itself dies. kill -9 parent terminate zombie processes
orphan process is a process whose parent process has terminated. so having init (process id � 1) as parent # ps -elf | head -1;
kill [SIGKILL|-9] PID //default SIGTERM gracefully with resource save released [immedaitely]
pkill | killall fire[fox] //by regex name
 
rpm -i(install)|U(upgrade)|e(remove)v(verbose)h(display) [�nodeps(skip dependencies)] pkg.rpm
rpm -q[l]|a [pkg] //list files | all [spec] installed pkg
rpm -q[p]R pkg[.rpm] (query dependencies) -qi|c[p] pkg[.rpm] (query info|config)  -q[c]f file (Query RPM Package [config} of a file/cmd)
 
scp (secure copy)  across ssh connection
scp user1@server1:/path/to/file user2@server2:/path/to/folder/ between linux host
download pscp.exe from same putty web
pscp user@remote-server:/path/to/remote-file c:\path\to\local-folder\  between linux and windows host
lftp -u srcusr,srcpwd -e|r [�only-newer] 'mirror /home/srcusr/public_html /home/destusr/public_html' ftp.srcserver.com //trans file from src server to local dest, clean dest first | push back
 
sort -n -k4 data.txt > sort.txt //numerical sort on 4th col
sed 's/old/new/' | -n '/filt/p' a.txt > b.txt //replace old with new | filter lines contains filt in txt
 
tar(-r|t|x|c[v display]f[z] file.tar[.gz] | [-C:extract to spec dir] dir [file1 file2] add|list|extract(same name)|combine[de|compress by g|unzip] dir or many files to 1
 
vim|less [+10] f.txt //> edit mode [start at line 10]
[i|o] //edit mode > insert mode at cur|new line
[esc] insert mode > edit mode: u (Undo), dd (Delete line), x|r [new char]|Y|p(Delete|replace|copy line|paster char at cursor), .(repeat last command)  i (>insert mode)
[:] edit mode > file mode w|q|! (save|quit|force) /|? (forward|backward search (case senstive), shift-N|n to prev|next  set num(show linenumber) 10(goto line 10)  i (>insert mode)
move cursor: shift-G|g or GG|gg(to file end|begin), 12G|gg to line 12, H|L(top|bottom of window), CTRL+F|B (for|backward one window), '(to previously modified line).
 
which <filename> //returns the matching path/file which would be executed in the current context
whereis python //list dirs of python src doc bin
file|whatis <filename|command> //info about it
 
http://www.dedoimedo.com/computers/grub.html
/boot/grub/menu.lst|grub.cfg:
root (hd0,1)//locate config at 2nd partition in 1st HD 
kernel /boot/vmlinuz-xxx//boots the kernel image at same partition
/sbin/grub-install /dev/hda //install GRand Unified Bootloader stage1 (point to stage2 config above) into Master Boot Record (MBR) 1st sector of 
1st HD (boot dev)
 
su [usr(default root)] switch user with target user�s password till exit|ctrl-D, sudo <cmd> to execute one line command as root with  own password
visudo edit+validate sudo perm on /etc/sudoers wheel group: %wheel ALL=(ALL)# Allows people in group wheel to run all commands, add usr to wheel grp
 
fdisk -l | /dev/sda //list partitions | cmd mode > d(elete) n(ew), 
pvcreate|resize /dev/sdb1/2 //create physical vol based on partitions created from previous step
vgcreate|display vg1 /dev/sbd1 /dev/sbd2 //create a virtual group contain physical volumes
lvdisplay|create[extend]remove -L [+]1000 -n lv1|2 vg1 //logical volumes can extend by MB any time
mkfs|fsck[.ext4] /dev/sda5|vg1/lv1 //format|check
 
create partition (standard | swap | software RAID | physical volume(LVM))
LVM physical volume part many > 1 LVM Volume Group 1 > many add Logival Volumes (ext4(default)|xfs: max 16|100TB, meta journal for faster 
recovery) can span across physical volumes
RAID part many > 1 RAID device (RAID combines multiple small physical disk into a large logical unit, RAID distributes data across each disk in 
the array by breaking it down into consistently-sized chunks commonly 256K or 512k)
 
a subdir may mount on diff partition than its super dir, /usr/local store on diff other than rest part of /usr 
min part: swap(2|1xRAM<|>2GB 4:2 5:3 fs=swap devtype=LVM), /boot(250-500MB fs=ext4 devtype=std), /(root 5GB+ cover all subdir unless diff mount), free(1GB+)
opt part: /usr(4GB+ most content)   /var(3GB+ downloads updated packages) /home(100MB-10GB+ seperate from sys upgrade)
 
 
service crond (re)start|stop|status
crontab -e|l //edit|display tail /var/log/cron //sys journal
#min hour day mon dow  command
 25  19   *   6,12   1-5  $HOME/bin/get.pl [> /home/john/logs/backup.log 2>&1] #daily at 19:25 Mon-Fri in Jun and Dec, [direct error(2) to standard output (like echo) log file descriptor(&1)]
@reboot /usr/bin/dircproxy #after each reboot
 
usr/bin/at [-f jobs.txt] now +2 minutes/hours/days | 10:00 AM 6/22/2015/tomorrow/next week|monday [< jobs.txt] //once at spec time=batch
at> echo 'job' //exe by bin/sh, perm by /etc/at.allow|deny if allow not exist check deny  
at> ^d //end
atq (list user's); atrm jid (remove); at -c jid (show cmd)
 
 
sudo mount -t iso9660 -o loop /home/cur/Fedora-18-i386-DVD.iso /mnt/iso/ //after load can cd or umount /mnt/iso (temporily created), loop is a pseudo-device
 
root has perm to edit user/group stored at /etc/passwd|group
id cusr //show u|gid(root=0) group
usermod -d|g/G/s|l/U|L </cdir/cusr/>|<cgroup>|/bin/sh(default:bash)|<nusr> <cusr>//change prime dir|group/add more group/change user's shell|login name/un|lock
 
/sbin/init->upstart (invoked as the last step of the kernel boo,  1st/parent process create other processes based on /etc/inittab RUNLEVEL(allowed processes group)=0(halt)1(single user)2|3(multiuser cmdline:server)4(user definited)5(multiuser GUI:desktop)6(reboot) and set  environment PATH=/bin:/usr/bin:/sbin:/usr/sbin,  init records process termination in /var/run/utmp and /var/log/wtmp
telinit q|s|3 //tell init to reread etc/inittab|switch runlevel to single user|3  via msg /dev/initctl queue
Single User Mode boot as root in a system maintenance shell but network is not activated. Unlike rescue mode, local file systems are mounted.
/etc/init.d->rc.d/init.d/ has executables (daemon service process like atd crond auditd httpd:Apache sshd) during the boot,  /var/log/upstart/mysvc.log
svc definition /etc/init/mysvc.conf //ln -s /path/to/mysvc.conf /etc/init/ (symlink can be edit without sudo)
 
Upstart (Ubuntu 14.10- RHEL 6-)
description "My Svc"
start on runlevel [2345]
stop on runlevel [016]
respawn [limit 10 10] # Automatically restart process if crashed [stop if spawn 10 times in 10 sec]
script   
  chdir /path/to/release #working directory
  exec ./mysvc foreground
end script
 
init-checkconf /etc/init/mysvc.conf //validate in
sudo initctl reload-configuration
sudo initctl list [| grep mysvc]//registed svc
sudo initctl start|status mysvc
 
systemd (RHEL 7+)
system service(unit.type files) /bin/systemctl re|enable to auto start at boot, auto re|create a symlink to /usr/lib/systemd/system/mysvc.service from /etc/systemd/system/[multi-user.target.wants (based on Install section)]/mysvc.service (if created directly by root chmod 664 to readable to all,chmod a+x on executable make it runnable to all)
service svc start | status / chkconfig svc on|off | systemctl start(manual) | status / en(auto)|disable /is-active||enabled /daemon-reload  mysvc.service
service --status-all | systemctl list-units --type service --all
systemctl list-dependencies --before|after gdm.service //services are ordered to start before|after GNOME
 
[Unit]
Description=mysvc
After=syslog.target network.target auditd.service httpd.service //This unit starts only after those units are active dependencies on other units. The units listed in Requires are activated together with the unit.
Requires|Wants|Conflicts= depsvc.service //strong|weak|negative dependencies activate together
 
[Service]
Type=simple(default)//The process started with ExecStart is the main process of the service (systemd will daemonizing the process by fork it to a daemon), services are considered ready after the executable is runned
forking//The process started with ExecStart will spawns fork() a child process to be the main process (daemon) of the service. The parent process
 
(foreground) exits when the startup is complete, services are considered ready after the Main PID exits.
PIDFile=/var/run/[mysvc]/mysvc.pid //stable PID for the main process of the service recommended for type=forking
Environment[File]=/etc/sysconfig/mysvc //static $PARA=val
ExecStart[Pre|post]|Stop=/usr/local/bin/msvc {$PARA}//cmd to run upon[before|after]Start|Stop
ExecReload=/bin/kill -HUP $MAINPID //kill main process, systemctl reload-or-restart mysvc
KillMode=process
Restart=always|on-failure //restarted after its process exits|fail
RestartSec=90 //restart at 90 second intervals StartLimitInterval> StartLimitBurst x RestartSec
/By default, services which are started more than 5 times within 10 seconds are not permitted to start any more times until the 10 second 
interval ends.
StartLimitInterval=400 //restart max 3 times within 400 sec
StartLimitBurst=3 
 
[Install]
WantedBy=multi-user|graphical.target //non|graphical multi-user system simlar to runlevel 3|5, poweroff|rescue|reboot.target = runlevel 0|1|6
units.target to group systemd units through a chain of dependencies, graphical.target starts system services such as the GNOME Display Manager 
(gdm.service) or Accounts Service (accounts-daemon.service) and also activates the multi-user.target unit that starts other essential system  services such as NetworkManager.service and activates basic.target.
systemctl list-units --type target (current like cmd runlevel) | isolate xxx.target (change runlevel like cmd telinit)
getty(Login)local/remote-fs(File Sys)network|sockets|paths|swap|sysinit|timers.target
 
systemctl rescue|emergency single user(root) mount local file sys & important system services without network to repair system when regular boot  fail | mount only root file sys & few essentail service when fail to enter rescue mode
systemctl halt/poweroff/reboot / suspend | hibernate (saves the system state in RAM | HD and restore fast|slower without reboot, need | not  maintain power to RAM
replace /sbin/halt(cpu procs)/poweroff/reboot|shutdown -c (cancel) | -h now(gracefully with script)->/lib/upstart/reboot|shutdown
 
/etc/cron.daily/logrotate exe daily to rotate logs : /usr/sbin/logrotate /etc/logrotate.conf (generic Log rotation config for all the log 
files)
weekly //weekly rotation
rotate 4 //keeps a 4 rotation backup
create
dateext //mark old log with date as file extension
include /etc/logrotate.d  //apply to all log there
/var/log/wtmp { //override generic config for spec log that has no owner pkg to be config in /etc/logrotate.d/
    monthly
    minsize 1M
    create 0664 root utmp //create new empty log files after each rotation with specified permission, user and group.
    rotate 1
}
 
/etc/logrotate.d/yum //log config for each installed pkg like yum
/var/log/yum.log {
    missingok //not output error if logfile is missing
    notifempty //not rotate empty log
    size 30k //rotated only if > size
    compress       
    yearly
    create 0600 root root
}
logrotate -f /etc/logrotate.conf //enforce to test ignoring schedule
 
lsof -u|p <cusr|pid> //LiStOpenFiles by usr\process
lsof -i [:port] //net conn {proc listen on port]
kill -9 `lsof -t -u user` (kill user's procs) | -c ssh -c init (files open by proc name prefix)
 
netstat -[c][n][l][p][t] //{continuously}[ip faster than hostname][listening] [by process][tcp] connections with root perm, -s report
netstat -ao | find "pid" //all ports open by a process
yum install|update|remove sysstat //mgr package
vmstat (mem,procs,swap) -s|d 5 8 // all|disk stat every 5 sec for 8 times
ifstat -a (network interface RECEIVE|TRANSMIT),
ifconfig eth0 up|down / 192.168.2.5 netmask 255.255.255.0 broadcast 192.168.2.7
ip addr show / add|del 192.168.2.5 dev eth0 / link set eth0 up|down
/etc/sysconfig/network-scripts/ifcfg-eth0, /etc/init.d/NetworkManager restart

iostat [interval count] (CPU and I/O)
mpstat -P ALL [3 4] //CPU utilization every 3 sec for 4 times
pidstat | -p ALL | [-t] -p <pid> [3 4] //active|all|spec procs [& threads] -rh mem% usage -R schedule priority -G <name> procs contain the name
sar -u|r -o <reportfilename> [interval count] //sys perf rept on CPU|memory
iptraf �I eth0|all - Real-time Network monitor (need yum install iptraf)
 
nmcli con add con-name MyOffice|MyCafe ifname eth0|wlan0 type ethernet|wifi |ssid MyCafe
nmcli dev status/wifi list dis|connect | con show/mod/edit(interactive)/up|down id MyOffice|MyCafe
ip a [add|del 192.168.80.174 dev eth0] //list all network interfaces [add|del ip address]
ip link set dev eth0 down/up|<prop value> //dis/enable | set property like MAC: address 00:0c:29:33:4e:aa
 
iptables-multi iptables -A INPUT|OUTPUT -p tcp|udp  --match multiport --d|sports port1 ,|: port2 -j ACCEPT|DROP //packet to|from the host 
map to dest|src ports/range, service iptables save
 
sysctl to change Kernel Variables for devices /sysfs, processes /procfs, config /configfs
sysctl -p | grep mem //display current buffer settings
net.core.r|wmem_max = 16777216 //config TCP read|write buffer size in sysctl.conf
sysctl -p /etc/sysctl.conf //reset
 
/selinux (policycoreutils{semodule})
Security-Enhanced Linux SELinux policy rules are checked after Discretionary Access Contro rules, DAC access is controlled based only on Linux 
user and group IDs. SELinux mandatory access control are not checked if DAC rules deny access first.
sestatus (if enabled, log at /var/log/audit/audit.log)
access decisions are based SELinux context: user:role:type:level. SELinux rule policy is administratively-defined, enforced system-wide, and is 
not set at user discretion as DAC
/etc/selinux/config: SELINUX=enforcing|permissive(denials are logged but not enforced|disabled SELINUXTYPE=targeted|mls (protected by process|
levels)
g|setsebool <item>/-a | on/off //get|set spec/all policy on/off 
semanage login -l //linux login - SELinux user mapped by pam_selinux
sysadm|staff_u|r|t can su & sudo | sudo only
user|guest_u|r|t   no su & sudo, can|not exe in /home & /tmp or network access         
SELinux users are authorized for roles, and roles are authorized for domains
ls -Z /usr/bin/passwd //id -Z |ps -eZ contest of cur user|running procs
-rwsr-xr-x  root root system_u:object_r:passwd_exec_t:s0
ls -Z /etc/shadow
-r--------. root root system_u:object_r:shadow_t:s0
passwd_exec_t|shadow_t is domain|type for passwd|shadow, policy rule allow proc/cmd in passwd_t domain to access files of shadow_t type (domain 
transit).
chcon [-R] -t type file[dir]//temp change type [recursive],  perm add|del: semanage fcontext -a|d -t type file[dir]
 
Automatic Bug Reporting Tool (default abrt UID and GID = 173, data at  /var/spool/abrt)
yum install abrt-desktop|cli|-addon-vmcore with kexec-tools //GUI(Application>SystemTools>ABRT or abrt-gui &, double click item intto detail) | 
cmd (abrt-cli list [-d (detail) -v (verbsoe)]) | detect kernel panic (can not continue) with kdump (System ? Administration ? Kernel crash 
dumps),  
service abrtd status|start|stop //abrtd daemon, abrt-ccpp|oops to catch C++ crash|Kernel oops(can continue)
 
C++0x|11  gcc 4.4|7+
g++ [-c] test.cpp [-o result] //a.out [test.o]object without
g++ main[result]executable with main./result; -g|Wall|O[2] enable debug g++ for gdb|warning|optimize[more], -I<include path> if .h in diff dir, 
g++ -lm  link to libm.a
Conventional Compilation: Compile and optimize one file at a time and Link the results
LinkTimeOptimization Compilation :Convert source language to IL one file at a time, then compile and optimize when Link IL together. allows optimizations across files/modules, such as inlining function and propagating constants across files. 
GCC 4.5+ option -flto : gcc -o myprog -flto -O2 foo.c bar.c
 
Data.cpp  Data.h  Test.cpp (#include "Data.h" main())
g++ -c Data.cpp Test.cpp //Data.o Test.o, (g++ -o Data.cpp fail because
g++ no main) Test.o Data.o -o Main //link multiple object file to
g++ executable ./Main
 
g++ Test.cpp Data.cpp|o -o Main //directly generate executable skip g++ .o
 
Makefile consists of target files, dependencies and commands for compile
target:dependencies
<tab>command
all: Main //or default:
Main: Test.o Data.o
        g++ -g -Wall Test.o Data.o -o Main
Test.o: Test.cpp Data.h
        g++ -g -Wall -c Test.cpp
Data.o: Data.cpp Data.h
        g++ -g -Wall -c Data.cpp
clean: //$make clean
        rm -f Main *.o
usr/bin/make  //compile from bottom to up thru dependency tree in default Makefile or specify [-f file] in cur dir unless {-C dir] , only
recompile changed file unless force [-B],

download and cd extracted srcode dir, ./configure [--prefix /opt/mapp] > make > make install to local recompile and install exe to dir default /usr/local
 
gdb <executable>>l show code  > b <[file:]linenum>//breakpoint  > run (stop at breakpont) > step (into) | n (over) > print <var>(vector {all val}) > set variable v= 2 > bt(backtrack) > c(continue)|quit
/etc/abrt/abrt-action-save-package-data.conf ProcessUnpackaged = yes //enable crash report for local build gdb <executable> -c core | /var/spool/abrt/ccpp-2017-04-14-18:46:30-2486/coredump //dump file by  Segmentation fault 
 
[ulimit -c will return 0 means core dump file is not created, # ulimit -c 75000|unlimited set the size limit of core files to 75000 bytes|unlimited
enable core dump file to be created Wheneve the application crash:
/etc/profile  change ulimit -S -c 0 > /dev/null 2>&1  to ulimit -c unlimited >/dev/null 2>&1
/etc/sysctl.conf append
kernel.core_uses_pid = 1 //Appends the coring processes PID to the core file name
kernel.core_pattern = /tmp/core-%e-%s-%h-%u-%g-%p-%t //define core file location and naming pattern (executable filename,number of signal causing dump,hostname,PID|UID|GID of dumped process, time of dump)
fs.suid_dumpable = 2
also in /etc/security/limits.conf comment out \* soft    core            0
enable debugging for ALL apps # echo "DAEMON_COREFILE_LIMIT='unlimited'" >> /etc/sysconfig/init
Reload the settings from changed /etc/sysctl.conf # sysctl -p ]
 
#include "path/file"  search ./path/file first then system headers #include <file> search system headers /usr/[local/]include/[/c++/x.x.x/] /usr/lib/gcc/x86_64-redhat-linux/4.4.7/include
whereis gcc //cc: /usr/bin/gcc /usr/lib/gcc /usr/libexec/gcc
yum group list //available pkg grp sudo yum|apt-get install gcc-4.7 g++-4.7 //rhel|Ubuntu
 
/etc/yum.repos.d/DevToolset.repo
[DevToolset-2]
name=RedHat DevToolset v2 $releasever - $basearch #$releasever=6 $basearch=x86_64 #baseurl=http://puias.princeton.edu/data/puias/DevToolset/$releasever/$basearch/
baseurl=http://puias.princeton.edu/data/puias/DevToolset/6/x86_64/
enabled=1
gpgcheck=0
 
yum install | list [available] prefix\*mid\*|repolist|update --disablerepo=repo1,repo2 //exclude or enabled=0
 
yum install devtoolset-2 --skip-broken //to list all dependencies Processing Dependency: devtoolset-2-libstdc++-devel = 4.8.2-15.1.el6 for package: devtoolset-2-gcc-c++-4.8.2-15.1.el6.x86_64
Processing Dependency: devtoolset-2-runtime for package: devtoolset-2-gcc-4.8.2-15.1.el6.x86_64
Processing Dependency: policycoreutils-python for package: devtoolset-2-runtime-2.1-4.el6.noarch
 
yum install devtoolset-2-libstdc++-devel-4.8.2 //start with one has no Dependency
rpm -ivh --nodeps policycoreutils-python-2.0.83-29.el6.x86_64.rpm //from download at www.rpmfind.net for CentOS 6.8 for x86_64 yum install devtoolset-2-runtime-2.1
yum install devtoolset-2-gcc-4.8.2
yum install devtoolset-2-gcc-c++-4.8.2
yum install devtoolset-2-strace //auto get latest version trace interactions between processes and the Linux kernel,
yum install devtoolset-2-memstomp //identifies function calls that use overlapping memory regions
yum install devtoolset-2-gdb-7.6.1
yum install devtoolset-2-gdb-gdbserver //remote debug yum install devtoolset-2-elfutils //inspect and manipulate ELF files (Executable and Linkable Format executables, object code, shared libraries, coredumps)
yum install devtoolset-2-dwz //optimize DWARF (debugging data format) info contained in ELF files yum install devtoolset-2-binutils
 
yum install devtoolset-2-oprofile devtoolset-2-valgrind  devtoolset-2-dyninst devtoolset-2-systemtap //linux profiler| memory debugging leak|use dyninst with systemtap that monitor subsystem yum install devtoolset-2-perftools //comb above 4
 
/opt/rh/devtoolset-2/root/usr/  bin/gcc --version //4.8  include/c++/4.8.2/*.h   lib/gcc/x86_64-redhat-linux/4.8.2/*.a/s/o | include/*.h  lib64/valgrind|elfutils|systemtap|dyninst|memstomp|strace|dwz.so   libexec/gcc/x86_64-redhat-linux/4.8.2/cc1[plus](compiler)
ln -s /opt/rh/devtoolset-2/root/usr/bin|include|lib|lib64|libexec|share/* /usr/local/bin|include|lib|lib64|libexec|share/ //symlink make opt pkg to be in PATH & include header search, can not link to an existing file/dir,  find . -maxdepth 1  [-follow] -type l -delete remove all [broken] links in cur dir vs unlink 1by1
 
gcc --version //4.4 old
hash -r //Ubuntu: ln -s /usr/bin/gcc-4.8 /usr/bin/gcc
gcc --version //4.8 new
g++ -Wall -g main.cpp  -std=c++11 -o result
 
http://llvm.org/
Clang is much faster and uses far less memory than GCC, GCC supports more languages than clang (C/C++ only)
clang++ -std=c++11 -stdlib=libc++ test.cpp [-o test -I<libcxx-install-prefix>/include/c++/v1 -L<libcxx-install-prefix>/lib] //clang|++ / GCC|G++ 
is the C|++ compiler, libc++ is C++11 implementation of the C++ standard library (libstdc++) include new <atomic> <type_traits>

http://www.sourceware.org/gdb/current/onlinedocs/gdb/Threads.html
GDB debug: thread apply threadids|all bt, backtrace certain|all threads, info threads threadids, set print thread-events on
Valgrind a programming tool for memory debugging, memory leak detection, and profiling

UNIT test: google Gmock and Gtest, BOOST unit, CppUnit
CLion double return to add watch (rigth click> inspect), ctrl-[alt]-B declaration[definition], ctrl-[alt]-H type [call] hier, ctrl-D copyline, ctrl-N search class by initials of camel name, ctrl-[shift]-enter auto completion, ctrl-[shift]-/  comment, ctrl-shift-z redo, ctrl_alt-T surround ctrl_alt-L format ctrl_alt-O import alt-F7 usages of class, alt-delete safe delete, alt-enter quick fix, alt-insert generate ctr/setter, shift-F6 rename, shift-F9|10 debug|run F8|7|9 stepover|into|resume, shift-arrow to select, 
auto select . or -> after pointer, auto var not intellise, scroll right bar to magnify warn/error in line (right upper corner !/? btn all err/warnings), dislay reference{Data&}@0x28fe78: {data = , click value on variable to change during debug 1991840098}, pointer{Data*|0x2c1580}0x2c1580, big number like 2914816 means uninit or deallocated, debugger dropdown threads,
SIGSEGV (Segmentation fault) access deallocated or unallocated mem (fxp deleted mem via ptr, collection out of boundary, wild ptr (without =nullptr) 
SIGFPE (Arithmetic exception) divid by 0
SIGILL	an illegal instruction

add new class: create header only to put both class declaration and implementation into the header file. class implementation code will be copied into every file that #includes it, and get recompiled there. slow and will cause bloated file sizes. Second, if change the code in the header, then need to recompile every file that includes that header. while change the code in a .cpp file, only that .cpp file needs to be recompiled!
add to target choose one to include src file intellises
.cpp files have the same exact name and function arguments delcared. both files will compile independantly, but cannot link the 2 files together into a task because get an multiply defined symbol, fixed by  namespaces
 
data access take 1|8|400000 CPU cycle if data resides in data cache(cache hit)|main memory(cache missing)|disk(page fault)
Temporal|spatial locality if recently used a certain chunk of data, probably will need it again soon | if recently used the data at address X,
will ll probably soon need address X+1. so The cache remembering the most recently used chunks of data. It operates with cache lines, typically
sized 128 byte or so, so even only need a single byte, the entire cache line that contains it gets pulled into the cache, invalidate also based
on cacheline.
first search data cache, if cache missing, then reload from main memory or disk by units of cache line which size is >= data, it may load related
data since they are allocated together, which reduce cache missing later when accessing them, so declare var together if instructions access them
are toghther, most effective data structure for a cache is an array since elements are allocated continously.
2D array is stored row by row in the memory, for (i = 0 to 100//excced SYSTEM_CACHE_LINE_SIZE) { for (j = 0 to 10){ a[j][i]++ cross cache line
worse perf than  a[i][j]++ sequential by row minimize the number of cache misses
optimize tool such as cachegrind and perf (performance analyzing tool in Linux, perf stat -d myexe)
 
Direct mapped cache: Each memory chunk can only be stored only in one particular slot in the cache. by map the chunk with index to cache slot
(chunk_index % cache_slots), Two memory chunks that map to the same slot cannot be stored at same time - confliction like hashtable
N-way set associative cache Each memory chunk can be stored in any one of N particular slots in the cache.Commonly, chunks with indices with the
same lowest order bits will all share 16 slots.

Cache Coherence: multiprocessor system with a separate local cache memory for each processor, it is possible to have one copy in the shared memory and one in each local cache memory. When one copy is changed, the other copies  must be synced
Snooping: (for bus-based machines Not scalable) broadcast to all processors via bus, they snoop/monitor to see if they have a copy of requested data, 
Write-invalidate:Invalidate all copies of cache when a variable in local cache is updated, other processes have to read a valid copy either from the shared memory, or from the processor that modified the variable.
Write-update:When a local cache is updated, the new data is broadcast to all caches containing a copy of the data for updating them. 
Directory: (scalable) Keep track of what is being shared in 1 centralized place, point-to-point requests

bug only occur on multi-core not single-core: each core has its own cache, shared resource variable cached between cores supposed to be synced, 
if not, diff threads exe on diff core will act on diff shared value from diff cache, to solve, declare shared resource as volatile, so it won't involve cache, or dedicate a core to a  process so all threads of it access the same cache.   
CPU affinity (kernel scheduler property "bonds" a process to specific CPU[s]) 
avoid costly sync op: whenever a processor adds a data to its local cache, all the other processors in the system also caching it must invalidate that data  
real-time application have dedicate CPU

# up2date schedutils //install schedutils (Linux scheduler utilities) package which is not installed by default 
# taskset -c 0,4 -p 13545 //bind process id to cpu list

set -e beginning of shell script  to exit immediately if any command exits with a nonzero exit value.

user application|kernel mode drivers and OS runs in user|kernel mode virtual address (user app crash wont impact system), Kernel mode drivers can access user virtual address but vice versa is not true 
read|write|General memory barriers(r|w|mb) guarantee read|write|all memory accesses specified before the barrier will happen before read|write|all memory accesses specified after the barrier.

http://linux-tutorial.info/modules.php?name=MContent&pageid=81 http://www.advancedlinuxprogramming.com/alp-folder/
linux kernel divides memory into physical|virtual managed by buddy system |process address space

Linux kernel (file /vmlinuz) implements a demand paged virtual memory system: All memory (physical RAM + swap space,Linux supports up to 64 GB of physical memory and several TB of swap ) seen by the user programs is virtual, Each process has its own isolated virtual address space. all memory are divided into pages(4,096 bytes per page).if physical memory is full, linux started using swap space/device (separate disk area configured by 'mkswap' 'swapon' command). demand paging: only loading virtual pages into memory as they are accessed, When a program tries to access memory, a virtual-to-physical translation is made, The Linux kernel checks the vm address determines which page of physical memory to make available. if it is not in physical mem,a page fault (not error) occurs, if it is valid (the prog has access to the mem) kernel reads the page from the swap space (won't delete)  into physical memory (accessing the hard disk is hundreds of times slower than accessing memory), possibly swap another existing page out to disk. Linux uses Least Recently Used (The more that a page is accessed, the younger it is) Old pages (age = 0)are good candidates for swapping. If that old page has not been modified, old page can be simply discarded because the original image is still in swap space, if modified (dirty page), are saved in a 'swap file' when removed from memory, swap cache is a list of page table entries each record a dirty swapped out page and its location in swap file. If the page is brought back to physical memory and swaped out again without being modified, will check swap cache to avoid duplicate write to swap file, if being modified, its entry is removed from the swap cache.  
mem_map_t data structure describes a single physical page: 
.count: number of users, >1 shared between  processes  
.age: The more that a page is accessed, the younger it is 
.map_nr: the physical page frame number that this mem_map_t describes. 
Each element of the free_area vector has a list mem_map_t of free blocks of pages for that sized block: [0]single page blocks, [1]2 pages blocks, [2]4 pages blocks...   

Linux uses the Buddy algorithm 2 to effectively allocate and deallocate blocks of 1 page, 2 pages, 4 pages and so on. first searches for blocks of pages of the size requested. It follows the chain of free pages that is queued on the list element of the free_area data structure. If no blocks of pages of the requested size are free, blocks of the next size (which is twice that of the size requested) are looked for. This process continues until all of the free_area has been searched or until a block of pages has been found. If the block of pages found is larger than that requested it must be broken down, for example if a block of 2 pages was requested, but first found free block is of 4 pages, then it will be broken down by half, The first half block would be returned to the caller as the allocated pages and the second block would be queued as a free block of 2 pages onto element [1] of the free_area. 
Whenever a block of pages is freed, the adjacent or buddy block of the same size is checked to see if it is free. If so combine to form a new free pages block of next/larger size. 
   
mapping the virtual memory address to the physical address is stored in page table, which is also hardware-cached in the processor.  
 
memory mapping:executable image is only mapped into the process's virtual memory space instead of loaded in mem. Every process' virtual memory is represented by an mm_struct data structure contains info about the image that it is currently executing and has pointers to a set of vm_area_struct data structures generated upon mem map, each represents a part of the executable image (executable code, initialized data). only the first part of executable image is actually brought into physical memory. As the image executes, upon demand paging it generates page faults and Linux uses the process's memory map to determine which parts of the image to bring into memory for execution. 
Memory mapped files are read a page at a time and these pages are stored in the page cache. upon demand paging kernel will check if the page is already present in the cache, not need to reloaded from disk. Buffer Cache contains buffers read from or being written to physical devices. The pages held in those caches are good candidates for being freed because discarding those pages is relatively easy as it requires no writing to disk and does not have too many harmful side effects.  
 
Boost.Interprocess,Remote Call Framework  
shared memory segmant across processes for fastest interprocess communication (it does not require a system call or entry to the kernel also avoids copying data)
one process must allocate the segment, rest attach the segment. after each process detaches the segment.one process must deallocate the segment.
Each shared memory segment should be explicitly deallocated, Invoking exit and exec detaches memory segments but does not deallocate them.

#include <sys/shm.h> <sys/stat.h>
int main ()
{struct shmid_ds shmbuffer;
const int shared_segment_size = 0x6400;
(int) segment_id = shmget (IPC_PRIVATE, shared_segment_size,IPC_CREAT | IPC_EXCL | S_IRUSR | S_IWUSR);/* Allocate: IPC_EXCL excelusive: create new instead of using existing */
//(int) segment_id = shmget (shm_key, getpagesize (), IPC_CREAT | S_IRUSR | S_IWUSER); /*Allocate a new shared memory segment (or access to an existing one, if shm_key is already used) that�s readable and writeable */
(char*) shared_memory = (char*) shmat (segment_id, 0, 0);/* Attach */
shmctl (segment_id, IPC_STAT, &shmbuffer);/* Determine the segment�s size. */
(int) segment_size = shmbuffer.shm_segsz;
sprintf (shared_memory, �Hello, world.�);/* Write a string to the shared memory segment. */
shmdt (shared_memory);/* Detach */
shared_memory = (char*) shmat (segment_id, (void*) 0x5000000, 0);/* Reattach at a different address. */
printf (�%s\n�, shared_memory);/* read string from shared memory. */
shmdt (shared_memory);/* Detach */
shmctl (segment_id, IPC_RMID, 0);/* Deallocate */
return 0;
}

% ipcs -m  //list of shared memorys and status
% ipcrm shm 1627649 //remove by shmid 

kernel does not synchronize accesses to shared memory,does not guarantee exclusive access even IPC_PRIVATE, each user can read & write, processes must sync access to shared memoryby like semaphores.
Linux provides Process semaphores for synchronizing processes, are initialize|allocated|deallocated (semctl|semget|semctl) and used like shared memory segments.

(int) semget (key, 1, sem_flags);//allocate: return id of a semaphores set containing 1 Semaphore with permission flag
(int) semctl (semid, 1, IPC_RMID, ignored_argument);//initialize|deallocate a semaphores set (id=semid) containing 1 Semaphore, 
[ignored_]argument: union semun{ unsigned short int *array;}//pointer to an array of unsigned short values. Each value is used to initialize one semaphore in the set.
unsigned short values[1];values[0] = 1;argument.array = values;
(int) semctl (semid, 0, SETALL, argument)

#include <sys/types.h> <sys/ipc.h> <sys/sem.h>
int binary_semaphore_wait|post (int semid)
{struct sembuf operations[1];
operations[0].sem_num = 0; //Use the first (and only) semaphore here
operations[0].sem_op = -1|1;//wait: Block until 1, then decrement to 0 | post: increment to 1 then return
+i: semaphore value is incremented by i
0: operation blocks until the semaphore value = 0
-i: semaphore value is decremented by i -> if semaphore value < 0 then blocks until the semaphore value = +i
operations[0].sem_flg = SEM_UNDO|IPC_NOWAIT;//Linux auto undoes the operation on the semaphore when the process exits | prevent the operation from blocking;
return semop (semid, operations, 1);//1:operations.length 
}

Semaphores continue to exist even after all processes using them have terminated.The last process to use a semaphore set must explicitly deallocate it
user ID of the calling process must match that of the semaphore�s allocator (or the caller must be root).
% ipcs -s //display information about existing semaphore sets
% ipcrm sem 5790517 //remove by semid

Mapped memory (=shared memory+associated file, allow different processes to communicate via a shared file) splits the file into page-sized chunks and then copies them into virtual memory pages
#include <sys/mman.h>
(int) fd = open ("/tmp/integer-file", O_RDWR, S_IRUSR | S_IWUSR);//file descriptor
file_memory = mmap (0, FILE_LENGTH, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_SHARED, fd, 0);
//memory address NULL/0 allows Linux to choose an available start address. MAP_SHARED immediately transferred change to the underlying file and made visible to other processes
close (fd);
scanf (file_memory, �%d�, &i);//read
sprintf ((char*) file_memory, �%d\n�, 2 * i);//double and write
munmap (file_memory, FILE_LENGTH);//manual Release the memory / auto Release upon exit

each process has a different virtual address space, they can share function pointers via shared|Mapped memory
Process A can send signal to B. But that signal can be obtained from kernel only, find_task_by_pid (PID of process B)  return task_struct, send_sig_info( task_struct,signal name) 
Dynamic libraries executing code shared between processes. good candidates for swapping out second to page and buffer caches.  

stack mem limit: set|getrlimit (only affect the cur process) or ulimit to reset other than default (8MB)
32-bit system - the max memory you can allocate per process is 3GB.
64-bit system - max is some large number >>1TB.

kernel decodes the network packet and copy the data from the kernel space to user space, this context switching constitutes about 40% of the network overhead.
to improve the network performance Kernel Bypass takes the kernel/ OS out of communication between the user space process and the I/O  network, eliminates the context switching and potentially the copy from the kernel space to user space, Customized kernel device driver. netmap and DNA to map I/O memory into userspace
 
#MARKET DATA FEED http://www.codeproject.com/Articles/553206/An-Introduction-to-Real-Time-Stock-Market-Data-Pro
Level 1 | 2 data = Trade&quote | Depth updates
Don't  using trade updates testing intraday strategies because trade price won't always reflect the actual price you could buy or sell for at that time.
depth updates contain change (NEW|UPDATE|DELETE quantity) to every order (Unique Order Id) in the order book queue, required for back-testing intraday trading strategies where orders will enter book queue rather than executing immediately
updates sent to related security, strategy listen to update events from specified set of securities

Low latency: low latency to 0.7-2 microseconds 1s=1000ms 1ms=1000us(microseconds) 1us=1000ns(Nanoseconds)
Latency Transmission (Convert data to bits) Propogation (Move bits across a network) Processing (process data through middleware (feed handlers) to trading systems (algo/strategy engines), 40 microsec internal latency from feed handler to consumer app
Colocation moved execution servers from the customers physical location (millionsec) to a physical position of the execution venue servers (microsec) as close as possbible for zero latency.  
Nasdaq TotalView ITCH feed, can have data rates of 20+ gigabytes/day with spikes of 3 megabytes/second or more. packet average 350 bytes, and each packet contains average 15 messages, most are National Best Bid/Offer (NBBO) quote messages average about 20-50 bytes each so this means handling 100,000-200,000 messages per second during high volume periods.
OPRA peak 2 million msg/sec NYSE 1 million msg/sec (http://www.marketdatapeaks.com/ average: 500k-1.5M)
marketmake trade 3mln/day, 20-100k trades/sec (50-10 millionsec/trade)

NYSE Amex, NYSE Arca, bats, directedge (EDGA, EDGX), NASDAQ (itch 4.0 binary soapbintcp 3.0 protocol:quote status|ouch:orders exe, UTP Quotation|Trade Data Feed:UQ|TDF), opra (options data from International Securities Exchange (ISE) Chicago Board Options Exchange(CBOE) CME(futures using FIX) BOX(boston options exchange) BATS(Pitch) ARCA AMEX NASDAQ),Consolidated Tape System (CTS) and Consolidated Quote System (CQS) data streams

FIX 5.0, FAST 1.1(FIX Adapted for STreaming : QuickFAST C++, OpenFAST.NET)
http://www.onixs.biz/directConnect/cme.php CME FIX/FAST Market Data Handler 
https://github.com/csinitiative/fhce/tree/master/feeds
http://openmarketdata.org/
arca / multicast / common / parse_messages.c
#include "fh_msg.h"// Exchange-provided FAST codec headers
FH_STATUS fh_parse_init(fh_shr_lh_proc_t *process)
{gaplist = fh_shr_gap_fill_new
 //init gap tracking linked list fh_shr_gap_fill_list<fh_shr_gap_fill_node.seqno|size|timestamp>.count|timeout

FH_STATUS parse_pkt(uint8_t *packet, int length, fh_shr_lh_conn_t *conn)//Entry point for parsing packet
{fh_shr_gap_fill_flush(gaplist);//delete expired gaps 
 for (i = 0; i < pkt_header.msg_count; i++)//process each message in the packet 
 {
parse_msg(pkt_header.seq_no + i, packet, length, conn))

int parse_mesg(uint64_t seq_no, uint8_t *buffer, int length,
 fh_shr_lh_conn_t *conn)
{fh_shr_lh_conn->fh_shr_lh_line->next_seq_no 
 if(seq_no < next_seq_no)
 {gapnode = fh_shr_gap_fill_find(gaplist, seq_no);
  if (gapnode != NULL){msg in gaplist} else {msg is dup}
 
 if(seq_no > next_seq_no)//it is a gap, add to gaplist
 {fh_shr_gap_fill_push(gaplist, next_seq_no, seq_no - next_seq_no);
  next_seq_no = seq_no;
//reset seq no 

 if(seq_no == next_seq_no)//normal
 {msg_type = *(char *)buffer;
 //1st char of packet is type   
  switch (msg_type) {
    case 'E':
 fh_parse_order_exe_msg(buffer, msg_length, conn, &data, &data_length)
    case 'P':
 fh_parse_trade_msg(buffer, msg_length, conn, &data, &data_length)


FH_STATUS fh_parse_trade_msg(uint8_t *buffer, int length,
 fh_shr_lh_conn_t *conn, void **data,
 int *data_length)

{fh_msg_trade_t    message;//fh_msg_trade<fh_msg_header.seq_no|timestamp>.order_no|stock|price|shares 
 message.order_no = fh_parse(buffer + 1, 12);

 message.buy_sell_ind    = *(char *)(buffer + 13)
 message.shares = fh_parse(buffer + 13, 6);

 message.match_no = fh_parse(buffer + 19, 12);
 memcpy(message.stock,      (char *)(buffer + 20), 6);
    
 message.price           = fh_parse(buffer + 26);
 message.header.seq_no    = conn->line->next_seq_no;
    
 message.header.timestamp = conn->timestamp;

inline int parse_symbol|firm_mapping(struct msg_body* body, char* msg_ptr, int msglngth)
{

    if(msglngth < (int) sizeof(ArcaL2Symbol)){return 0;}
    body->symbol_index = big_endian_16(msg_ptr);
    body->session_id = (unsigned char) *(msg_ptr+2);
    memcpy(&(body->symbol),msg_ptr+4,ARCABOOK_SYMBOL_LENGTH);

inline int parse_firm_mapping(struct msg_body* body, char* msg_ptr, int msglngth)
{
    if(msglngth < (int) sizeof(FirmUpdate_t)){return 0;}
    body->firm_index = big_endian_16(msg_ptr);
    memcpy(&(body->firm),msg_ptr+7,ARCABOOK_ATTRIBUTION_LENGTH);
arca / multicast / common / publications.c


filter out "bad" ticks (margin data exceed threshold) coming from real or simulation market data providers. 
if (Math.Abs((1 - lastGoodTrade.Price / trade.Price) * 100) < 0.5)/// check if new trade differs from the last good not more than on 0.5%

mkt dt hdlr parse msg into obj and store to hashtable by symbol for quik search, read-write lock to ensure latest data, update existing obj or use new placement to avoid mem allocation, broadcast to consuming app via tibco
tibco reliable mode (with performance cost) provide reliable delivery (resend) of data but not guaranteed,realtime market data (quota) becomes stale after few seconds and resend is meaningless 
Certified messaging guarante delivery for orders msg based on registration (Receiver registers with Sender by subscribe on a topic) and acknowledgment (Sender waits for ack from receiver, keep un-acked msg in mem|file ledger) 

#FINANCIAL INFORMATION EXCHANGE http://www.cmegroup.com/confluence/display/EPICSANDBOX/Session+Layer+-+Resend+Request http://javarevisited.blogspot.com/2011/02/fix-protocol-session-or-admin-messages.html
if receiver receive a SeqNo <|> expected, will drop session|request sender to resend
receiver FIX Engine uses Resend Request (tag 35|MsgType=2) if a sequence number gap is detected or lost a message with tag7|BeginSeqNo=2  tag16|EndSeqNo=5 (0 means resend all following msg)
as response to Resend Request, sender FIX Engine uses Sequence Reset|Gap Fill (tag 35|MsgType=4) to  fill the place of stale message that  sender FIX Engine does not want to resend, with tag36|NewSeqNo=3 tag43|PossDupFlag=Y and tag123|GapFillFlag=Y, (N/empty means Reset mode ONLY be used to recover from a disaster situation which cannot be otherwise recovered by "Gap Fill" mode.
incoming and outgoing sequence numbers are reset as part of EOD (end of day)

FIX vesion (8) new single order Message:Type(35)=D Seq(34) Price(44) Side(54) OrderQty(38) SecurityID(48)  OrdType(40)  
SecurityType(167) EQUITY CS common stock or CORP bond etc, CFICode (461) options-based, futures-based etc
Symbol(55) = SecurityID(48) with SecurityIDSource(22)(e.g. CUSIP, SEDOL, ISIN, etc)
MsgType (35)=A(Authentication) 0(Heart Beat) 1(Test Request) D(New Order) 2(Request Resend) 8(Execution Report with OrdStatus39, Ack of Confirm|Cancel order) 9(Order Cancel Reject [ <102>  CxlRejReason 0 = Too late to cancel] F|G(Cancel|/Replace with ClOrdID(11):new,OrigClOrdID(41):previous )
ExecType (150) descibe the event that occured during executing previous request 4(cancell) 5(replace) that cause the Execution Report (MsgType=8)  being issued 
OrdStatus (39) defines the current state of the order 0(new) 1(parital filled) 2(filled) 4(cancelled) 5(replaced) 8(rejected) 6|9 Pending Cancel|Replace result of F|G
fxp:sent a replace request to reduce order quantity to what was already partially filled. In response get an execution report of order status 2 (Filled) and execution type 5 (Replace). 

ClOrdID(11) assigned by the institution(unique in firm), used to identify the previous order in cancel/replace requests.
OrdID(37) Unique per day for Order as assigned by broker, and used to match ack from exchange with order placed
if no ack received, the order need to be resent or cancelled, If a cancel ack is received prior to a fill, usually close the order and reject the fill.

LeavesQty (151) quality is left to be executed on the order partifully filled.
smart rout order: v5.0 execution instruction ExecInst(18)=g (External Routing Allowed)  v4.4 HandlInst (21=1 auto, 2 auto but intervention ok, 3 manual:CARE ), ExDestination (100) or SecurityExchange (207)
Session level Reject (MsgType 35=3) failed on session-level rules validation e.g. unknown MsgType (35=99), checksum (tag 10), BodyLength (tag 9) 
Business Message Reject (MsgType 35=j) to reject an application-level message after passes all session-level rules 
Don�t Know Trade (DK MsgType = Q): execution reject message fxp ClOrdID in order no match exec rept
OrderCapacity <528>  A=Agency G= Proprietary I= Individual; OrderRestrictions <529> Market Maker, Program Trade,[Non]Index Arbitrage
multiple sessions by one connection to server by unique SenderCompID sender ID sending message to TargetCompID (target Server Id to connect) per session

the FOK (fill or kill) requires the entire order to be filled or none of it will while the IOC (immediate or cancel) permits partial fills at the limit price
Indication of Interest(IOI): non-binding interest in buying a security that is currently in registration by the SEC. 

Appia Ullink OnixS,QuickFIX (open src FIX enginee quickfixengine.org) comes with a .NET wrapper written in managed C++. This enables any CLR based language (i.e., C#, VB.NET) to access QuickFIX. download quickfix-1.12.4.zip source or quickfix-bin-vs8-1.12.4.zip binary (vs2005), open source quickfix.sln with vs and build with config_windows.h file :#define HAVE_MSSQL 1 (Compiles MSSQL support into QuickFIX. If you enable this option, the mssql include and library directories must be in the Visual Studio search paths.) run src/sql/mssql/create.bat under sa without pwd. build generates quickfix_net.dll and quickfix_net_message.dll that are referenced from .net client application. quickfix_net.dll contains object model for entity like acceptor, account, order, price, quote,quantity,securtiy, trade. quickfix_net_message.dll contians MessageFactory and MessageCracker,  object model for fix msg like newOrderlist/single, orderstatus/cancel/replacerequest,  Quote Request, allocation, SettlementInstruction, reject.
 public static void main(String args[])//console or window service
 {    String fileName = args[0];//config file 
      SessionSettings settings = new SessionSettings(new FileInputStream(fileName));
      Application application = new MyApplication();
      FileStoreFactory storeFactory = new FileStoreFactory(settings);
      FileLogFactory logFactory = new FileLogFactory(settings);
      MessageFactory messageFactory = new DefaultMessageFactory();
      //listner on FIX engine message in FileStore
      SocketAcceptor acceptor = new SocketAcceptor
        (application, factory, settings, logFactory /*optional*/, messageFactory);
      acceptor.start();
      // while( condition == true ) { do something; }
      acceptor.stop();
setting is loaded form config file
  # default settings for sessions 
  [DEFAULT] 
  ConnectionType=initiator 
  ReconnectInterval=60 
  SenderCompID=TW 
  
  #multiple session definition, a session (message) is identified by BeginString?SenderCompID TargetCompID, FIX4X.XML is FIX  format file based on which the message is validated. 
  [SESSION] 
  # inherit ConnectionType, ReconnectInterval and SenderCompID from default 
  BeginString=FIX.4.1 
  TargetCompID=ARCA 
  StartTime=12:30:00 
  EndTime=23:30:00 
  HeartBtInt=20 
  SocketConnectPort=9823 
  SocketConnectHost=123.123.123.123 
  DataDictionary=somewhere/FIX41.xml 

  [SESSION] 
  BeginString=FIX.4.2 
  TargetCompID=INCA 
  StartTime=12:30:00 
  EndTime=21:30:00 
  # overide default setting for RecconnectInterval 
  ReconnectInterval=30 
  HeartBtInt=30 
  SocketConnectPort=6523 
  # (optional) alternate connection ports and hosts to cycle through on failover 
  SocketConnectPort1=8392 
  SocketConnectHost1=8.8.8.8 
  SocketConnectPort2=2932 
  SocketConnectHost2=12.12.12.12 
  DataDictionary=somewhere/FIX42.xml 


//requesting to be notified of events that occur on the FIX engine by implement QuickFix.Application interface.
      class MyApplication: QuickFix.Application, QuickFix.MessageCracker

	{   
	 public overide void onCreate(SessionID sessionID){..}//session is created
    	 public overide void onLogon(SessionID sessionID){..}
    	 public overide void onLogout(SessionID sessionID){..}
    	 public overide void toAdmin(Message message, SessionID sessionID){..}
    	 public overide void toApp(Message message, SessionID sessionID){..}
    	 public overide void fromAdmin(Message message, SessionID sessionID){..}
    	 public overide void fromApp(Message message, SessionID sessionID)
	 {//where buyer receive order msg and seller receive exe ack msg
  		crack(message, sessionID);//generic MessageCracker.crack the msg with diff types and fire onMessage event 
	 }

	 public override void onMessage(QuickFix42.NewOrderSingle/OrderCancelRequest message, QuickFix.SessionID sessionID)
	 {//read typed field defined in quickfix_net.dll out of typed message defined in quickfix_net_message.dll
  	  ClOrdID clOrdID = new ClOrdID;
  	  message.get(clOrdID);
  	  ClearingAccount clearingAccount = new ClearingAccount();
  	  message.get(clearingAccount);
	 }
	}
void sendOrderCancelRequest() 
{ OrderCancelRequest message = new OrderCancelRequest(new OrigClOrdID("123"),new ClOrdID("321"),new Symbol("LNUX"),new Side(Side.BUY));
Session.mansendToTarget(message, "senderCompID", "targetCompID"); 
}

